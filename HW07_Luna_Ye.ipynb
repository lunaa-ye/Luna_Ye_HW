{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee50f676",
   "metadata": {},
   "source": [
    "# Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77cf1059",
   "metadata": {},
   "source": [
    "### Difference Between Simple Linear Regression (SLR) and Multiple Linear Regression (MLR)\n",
    "- **Simple Linear Regression (SLR):**\n",
    "  In SLR, we model the relationship between a single predictor (independent variable) and an outcome (dependent variable). The form of the equation is:\n",
    "  \n",
    "  $\\text{outcome} = \\beta_0 + \\beta_1 \\cdot \\text{predictor} $\n",
    "  \n",
    "  where $\\beta_0$ is the intercept, and $\\beta_1$ represents the slope or the effect of the predictor on the outcome.\n",
    "\n",
    "- **Multiple Linear Regression (MLR):**\n",
    "  In MLR, we model the outcome using two or more predictors. This allows us to capture more complex relationships. The form is:\n",
    "  \n",
    "  $\\text{outcome} = \\beta_0 + \\beta_1 \\cdot \\text{predictor}_1 + \\beta_2 \\cdot \\text{predictor}_2 + \\ldots + \\beta_k \\cdot \\text{predictor}_k$\n",
    "  \n",
    "  where $\\beta_0$ is the intercept, and each $\\beta_i$ represents the effect of a specific predictor on the outcome.\n",
    "\n",
    "- **Benefit of MLR Over SLR:**\n",
    "  MLR allows us to include multiple factors to explain the variability in the outcome, providing a more nuanced model. For example, predicting housing prices using both square footage and location may be more accurate than using square footage alone.\n",
    "\n",
    "---\n",
    "\n",
    "###  Continuous vs. Indicator Variable in Simple Linear Regression\n",
    "- **Continuous Variable in SLR:**\n",
    "  When we use a continuous predictor, we assume a linear relationship over the entire range of that variable. For instance:\n",
    "  \n",
    "  $\\text{outcome} = \\beta_0 + \\beta_1 \\cdot \\text{continuous predictor}$\n",
    "  \n",
    "\n",
    "- **Indicator Variable in SLR:**\n",
    "  An indicator variable takes on values like 0 or 1, representing two categories. This equation becomes:\n",
    "  \n",
    "  $\\text{outcome} = \\beta_0 + \\beta_1 \\cdot 1(\\text{indicator predictor})$\n",
    "  \n",
    "  Here, $\\beta_1$ represents the effect of the indicator predictor, essentially shifting the intercept depending on the category (0 or 1).\n",
    "\n",
    "---\n",
    "\n",
    "###  Effect of Adding an Indicator Variable to Create a Multiple Linear Regression\n",
    "- When a single indicator variable is added alongside a continuous variable, the MLR equation looks like:\n",
    "  \n",
    "  $\\text{outcome} = \\beta_0 + \\beta_1 \\cdot \\text{continuous predictor} + \\beta_2 \\cdot 1(\\text{indicator predictor})$\n",
    "  \n",
    "  - **Interpretation**: The continuous variable affects the outcome's slope, while the indicator variable shifts the intercept.\n",
    "  - **Model Behavior Change**: The model now represents two parallel lines with different intercepts, one for each category of the indicator variable. For example, this might model separate trends for two groups (e.g., male and female).\n",
    "\n",
    "---\n",
    "\n",
    "###  Effect of Adding an Interaction Term Between Continuous and Indicator Variable\n",
    "- Including an interaction term allows the effect of the continuous variable to differ based on the category. The equation is:\n",
    "  \n",
    "  $\\text{outcome} = \\beta_0 + \\beta_1 \\cdot \\text{continuous predictor} + \\beta_2 \\cdot 1(\\text{indicator predictor}) + \\beta_3 \\cdot (\\text{continuous predictor} \\cdot 1(\\text{indicator predictor}))$\n",
    "  \n",
    "  - **Interpretation**: Here, $\\beta_3$ represents the change in slope for the continuous predictor based on the indicator category.\n",
    "  - **Model Behavior Change**: This setup results in two lines with different intercepts **and** slopes, making it possible to capture distinct patterns for each category (e.g., one slope for females and a different one for males).\n",
    "\n",
    "---\n",
    "\n",
    "###  MLR Model Based Only on Indicator Variables for a Categorical Predictor\n",
    "- **When the Predictor is Categorical with \\(m\\) Categories**:\n",
    "  - We create \\(m - 1\\) binary indicator variables to represent the categories. For example, for three categories (say A, B, and C), we use two indicators:\n",
    "    - $1(\\text{Category B})$: 1 if the observation is B, otherwise 0.\n",
    "    - $1(\\text{Category C})$: 1 if the observation is C, otherwise 0.\n",
    "  - The equation becomes:\n",
    "    \n",
    "    $\\text{outcome} = \\beta_0 + \\beta_1 \\cdot 1(\\text{Category B}) + \\beta_2 \\cdot 1(\\text{Category C})$\n",
    "    \n",
    "  - Here, $\\beta_0$ is the baseline (the expected outcome for Category A), $\\beta_1$ shows the effect of being in Category B rather than A, and $\\beta_2$ the effect of being in Category C rather than A.\n",
    "\n",
    "- **Why $m - 1$ Indicators?**\n",
    "  Using $m$ indicators would make one redundant, as it introduces multicollinearity. By using $m - 1$, each category's effect is represented as a deviation from the baseline category (often the default or \"reference\" group).\n",
    "\n",
    "- **Model Behavior**: This model distinguishes the outcome based solely on category membership, with each $\\beta$ capturing the impact of a category relative to the baseline.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "362c5520",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af8c3e26",
   "metadata": {},
   "source": [
    "Here's a summary of our exchanges in this thread, tailored for submission:\n",
    "\n",
    "---\n",
    "\n",
    "**1. Distinction Between Simple and Multiple Linear Regression (SLR vs. MLR)**\n",
    "   - We reviewed the difference between SLR and MLR. SLR models the relationship between a single predictor and the outcome with a simple linear form, while MLR includes multiple predictors. We noted that MLR can capture more complex relationships by accounting for multiple influencing factors.\n",
    "   - Equations:\n",
    "      - SLR: \\(\\text{outcome} = \\beta_0 + \\beta_1 \\cdot \\text{predictor}\\)\n",
    "      - MLR: \\(\\text{outcome} = \\beta_0 + \\beta_1 \\cdot \\text{predictor}_1 + \\beta_2 \\cdot \\text{predictor}_2 + \\dots + \\beta_k \\cdot \\text{predictor}_k\\)\n",
    "   - The benefit of MLR over SLR is that it provides a more nuanced view by including additional predictors, which allows for better modeling of complex outcomes.\n",
    "\n",
    "**2. Continuous vs. Indicator Variables in Regression**\n",
    "   - We examined how continuous and indicator (binary) variables function in SLR. A continuous variable implies a smooth relationship across its range, while an indicator variable represents a categorical distinction (often as 0 or 1).\n",
    "   - Equations:\n",
    "      - Continuous predictor: \\(\\text{outcome} = \\beta_0 + \\beta_1 \\cdot \\text{continuous predictor}\\)\n",
    "      - Indicator predictor: \\(\\text{outcome} = \\beta_0 + \\beta_1 \\cdot 1(\\text{indicator predictor})\\)\n",
    "   - The difference affects the interpretation: a continuous predictor affects the slope, while an indicator shifts the intercept.\n",
    "\n",
    "**3. Introducing an Indicator Variable in MLR**\n",
    "   - When adding an indicator variable alongside a continuous predictor in MLR, the model represents two parallel lines with different intercepts based on the indicator's category.\n",
    "   - Equation:\n",
    "      - \\(\\text{outcome} = \\beta_0 + \\beta_1 \\cdot \\text{continuous predictor} + \\beta_2 \\cdot 1(\\text{indicator predictor})\\)\n",
    "   - This allows us to model separate trends for different groups, reflecting parallel but distinct lines in the data.\n",
    "\n",
    "**4. Effect of Interaction Between Continuous and Indicator Variables**\n",
    "   - Adding an interaction term between a continuous and an indicator variable allows the effect of the continuous variable to differ by group.\n",
    "   - Equation:\n",
    "      - \\(\\text{outcome} = \\beta_0 + \\beta_1 \\cdot \\text{continuous predictor} + \\beta_2 \\cdot 1(\\text{indicator predictor}) + \\beta_3 \\cdot (\\text{continuous predictor} \\cdot 1(\\text{indicator predictor}))\\)\n",
    "   - This creates two lines with different slopes and intercepts, capturing distinct patterns for each group.\n",
    "\n",
    "**5. MLR with Indicator Variables for a Categorical Predictor**\n",
    "   - For categorical predictors with multiple levels, we use multiple indicator variables, representing them as “number of categories minus one” binary variables. This allows the model to compare each category to a baseline group.\n",
    "   - Equation:\n",
    "      - \\(\\text{outcome} = \\beta_0 + \\beta_1 \\cdot 1(\\text{Category B}) + \\beta_2 \\cdot 1(\\text{Category C})\\)\n",
    "   - This approach models each category's effect relative to a reference group, useful in situations like comparing multiple regions or types.\n",
    "\n",
    "**6. Discussion on Ranges of Parameters in SLR and MLR**\n",
    "   - We discussed that \\(\\beta_0\\) (intercept), \\(\\beta_i\\) (coefficients), and the predictors themselves don’t have strict inherent ranges, as they depend on the data’s context and scale. For both SLR and MLR, \\(\\beta_i\\) can take any real value, influenced by the predictor scale and its relationship with the outcome.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9c0fa9",
   "metadata": {},
   "source": [
    "### Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4abf75f",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/6732347e-430c-8010-a21e-b436e94fc32f"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c9d942b",
   "metadata": {},
   "source": [
    "# Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce6b634e",
   "metadata": {},
   "source": [
    "In this scenario, the company’s goal is to predict the *sales revenue* (outcome variable) based on the *advertising budgets for TV and online campaigns* (predictor variables). Let’s denote these variables as follows:\n",
    "\n",
    "- **Outcome (Y):** Sales revenue\n",
    "- **Predictor (X1):** TV advertising budget\n",
    "- **Predictor (X2):** Online advertising budget\n",
    "\n",
    "### **Additive Model without Interaction:**\n",
    "   In the additive model, we assume that each advertising budget influences sales independently, without any interaction effect between TV and online advertising. The linear form of this model is:\n",
    "\n",
    "   \n",
    "   $Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon$\n",
    "   \n",
    "\n",
    "   Here:\n",
    "   - $\\beta_0$ is the intercept.\n",
    "   - $\\beta_1$ represents the effect of the TV advertising budget on sales.\n",
    "   - $\\beta_2$ represents the effect of the online advertising budget on sales.\n",
    "   - $\\epsilon$ is the error term.\n",
    "\n",
    "   In this form, the effect of the TV ad budget on sales is always $\\beta_1$, regardless of the online ad budget, and vice versa.\n",
    "   like multiple linear regression\n",
    "\n",
    "###  **Model with Interaction:**\n",
    "   If we hypothesize that the effectiveness of each advertising medium depends on the amount spent on the other (an interaction), we include an interaction term between TV and online advertising. The linear form of this model becomes:\n",
    "\n",
    "   \n",
    "   $Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 (X_1 \\times X_2) + \\epsilon$\n",
    "   \n",
    "\n",
    "   Here:\n",
    "   - $\\beta_3$ represents the interaction effect between the two advertising budgets.\n",
    "   - The $(X_1 \\times X_2)$ term captures how the effectiveness of one type of advertising changes based on the other’s budget.\n",
    "\n",
    "### Predictions and Interpretation:\n",
    "- **Without Interaction:** If we use the additive model, we predict sales by calculating the combined independent effects of each budget. The effect of increasing the TV budget, for example, does not depend on the online budget and is always equal to $\\beta_1$.\n",
    "- **With Interaction:** If the model includes the interaction term, the effect of increasing the TV budget on sales depends on the online budget. For instance, increasing the TV budget will have a different impact on sales when the online budget is high versus when it is low, as determined by $\\beta_3$.\n",
    "\n",
    "The main difference between these models is that the one with interaction reflects a synergistic or conditional relationship between TV and online advertising, whereas the additive model does not.\n",
    "\n",
    "---\n",
    "\n",
    "###  **Binary Predictor Scenario (High or Low Budgets):**\n",
    "   If we instead categorize the budgets as “high” (1) or “low” (0), then we have two binary variables. Let $X_1$ and $X_2$ be binary indicators for high TV and high online budgets, respectively.\n",
    "\n",
    "   #### **Additive Model with Binary Predictors:**\n",
    "   Without an interaction, the linear form is:\n",
    "\n",
    "   \n",
    "   $ Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon$\n",
    "   \n",
    "\n",
    "   Here, $\\beta_1$ is the effect on sales of a high TV budget, and $\\beta_2$ is the effect of a high online budget, regardless of each other’s status.\n",
    "\n",
    "   #### **Model with Interaction for Binary Predictors:**\n",
    "   With interaction, we have:\n",
    "\n",
    "   \n",
    "   $Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 (X_1 \\times X_2) + \\epsilon$\n",
    "   \n",
    "\n",
    "   Here, $\\beta_3$ represents the additional impact when both TV and online budgets are high, capturing any synergistic effects.\n",
    "\n",
    "### Predictions with Binary Variables:\n",
    "- **Without Interaction:** Predictions in the additive model will simply sum the independent effects of each budget level. For example, if both budgets are high, the sales prediction will be $\\beta_0 + \\beta_1 + \\beta_2$.\n",
    "- **With Interaction:** If both budgets are high, the sales prediction will be $\\beta_0 + \\beta_1 + \\beta_2 + \\beta_3$, indicating that the combined high budgets have an effect that is “more than the sum of its parts,” as determined by $\\beta_3$.\n",
    "\n",
    "In both scenarios, the model with interaction allows us to capture the potential for a mutually reinforcing effect between TV and online advertising budgets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ee63264",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4800d5c8",
   "metadata": {},
   "source": [
    "Certainly! Here’s a summary of our discussion on additive models, interactions, and their role in linear regression:\n",
    "\n",
    "---\n",
    "\n",
    "**Summary of Exchanges on Additive and Interaction Models in Linear Regression**\n",
    "\n",
    "1. **Scenario Overview**:\n",
    "   - We discussed a scenario where a company aims to predict sales revenue based on its advertising budgets for TV and online campaigns. The question centered on determining whether there is an interaction between these two advertising mediums—whether the effect of one type of advertising (e.g., TV) depends on the amount spent on the other (e.g., online).\n",
    "\n",
    "2. **Understanding Variables and Model Forms**:\n",
    "   - We identified the **outcome variable** as *sales revenue* and the **predictor variables** as *TV advertising budget* and *online advertising budget*.\n",
    "   - We covered the two primary model forms:\n",
    "      - **Additive Model without Interaction**: \\( Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\epsilon \\)\n",
    "      - **Model with Interaction**: \\( Y = \\beta_0 + \\beta_1 X_1 + \\beta_2 X_2 + \\beta_3 (X_1 \\times X_2) + \\epsilon \\)\n",
    "\n",
    "3. **Interpretation of Models**:\n",
    "   - In the **additive model without interaction**, each advertising budget independently affects sales, with no synergistic relationship.\n",
    "   - In the **model with interaction**, the effect of one budget depends on the level of the other, indicating a synergistic effect (or “more than the sum of its parts”).\n",
    "\n",
    "4. **Binary Predictor Scenario**:\n",
    "   - We examined the scenario where advertising budgets are categorized as either “high” or “low” (binary variables).\n",
    "   - The model forms for this case were similar, but with binary indicators instead of continuous variables. The interaction model in the binary case reflects whether a “high” budget in both advertising mediums has a greater effect than simply adding their individual contributions.\n",
    "\n",
    "5. **General Explanation of the Additive Model without Interaction**:\n",
    "   - We discussed the additive model in general, noting that it functions as a multiple linear regression model where each predictor contributes independently to the outcome.\n",
    "   - Key characteristics: the effects are independent of each other, linear, and have no interaction terms. This model type is suitable when the predictors’ effects on the outcome are believed to be separate and non-synergistic.\n",
    "\n",
    "---\n",
    "\n",
    "This summary captures our main points, covering definitions, interpretations, and model forms relevant to additive and interaction models in multiple linear regression."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1a7b79",
   "metadata": {},
   "source": [
    "### Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e728cf7",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/6734bc8b-a388-8010-86fb-2414aa7caf12"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879c6ce9",
   "metadata": {},
   "source": [
    "# Question 3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1291b94",
   "metadata": {},
   "source": [
    "1. **Logistic Regression**:\n",
    "   - Logistic regression is used when the outcome variable is binary (e.g., Yes/No, 0/1). It models the probability that a given input point belongs to a certain class, using a sigmoid function to transform the output of a linear equation to a probability between 0 and 1.\n",
    "   - In a logistic regression, the relationship between predictors (independent variables) and the log-odds of the outcome variable is linear. The log-odds transform allows us to interpret the model coefficients in terms of how the odds of the outcome change with a unit increase in the predictor variable.\n",
    "\n",
    "2. **Additive Specification**:\n",
    "   - This refers to a model where each predictor contributes independently to the outcome. For example, a linear combination of predictors without any interaction terms is an additive model. The outcome changes as the predictors change, but without interaction terms to indicate that one variable’s effect depends on another.\n",
    "\n",
    "3. **Synergistic Interaction Specification**:\n",
    "   - Here, predictors interact with each other, meaning that the effect of one predictor on the outcome variable may depend on the value of another predictor. This can help capture more complex relationships within the data.\n",
    "\n",
    "4. **Continuous, Binary, and Categorical Variables**:\n",
    "   - Continuous variables take on any value within a range (e.g., age, income).\n",
    "   - Binary variables represent two categories (e.g., 0 or 1 for “No” or “Yes”).\n",
    "   - Categorical variables have multiple categories that aren’t naturally ordered (e.g., marital status: single, married, divorced).\n",
    "\n",
    "5. **Log-Odds**:\n",
    "   - In logistic regression, the log-odds are the logarithmic transformation of odds, where odds are defined as the probability of an event occurring divided by the probability of it not occurring.\n",
    "\n",
    "### Implementing Logistic Regression\n",
    "\n",
    "#### 1. Preprocessing\n",
    "   - Load the CSCS dataset and clean the data (e.g., handle missing values, encode categorical variables).\n",
    "   - Convert categorical variables to binary if they are not already binary. For example, you can transform a multi-category variable into a binary form by creating separate dummy variables (one-hot encoding).\n",
    "\n",
    "#### 2. Defining Predictor and Outcome Variables\n",
    "   - Identify a binary or categorical variable to use as the **outcome variable** (dependent variable) by converting it to a binary format if necessary.\n",
    "   - Choose a mix of continuous, binary, or categorical predictors (independent variables) to include in the model.\n",
    "\n",
    "#### 3. Building a Logistic Regression Model with `statsmodels.formula.api`\n",
    "   - Use the `smf.logit()` function to fit a logistic regression model.\n",
    "   - Specify an **additive model** (e.g., `Outcome ~ Predictor1 + Predictor2`) and an **interaction model** (e.g., `Outcome ~ Predictor1 * Predictor2`)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dec0a730",
   "metadata": {},
   "source": [
    "\n",
    "- **Outcome Variable (Binary)**:  \n",
    "  - `COVID_vaccinated`: This could be transformed to a binary variable indicating whether an individual is vaccinated (1) or not (0).\n",
    "  \n",
    "- **Potential Predictor Variables**:\n",
    "  - **Continuous Variables**:\n",
    "    - `DEMO_age`: Age of the participant.\n",
    "    - `WELLNESS_life_satisfaction`: Measures life satisfaction, potentially influencing health behaviors like vaccination.\n",
    "  \n",
    "  - **Binary Variables**:\n",
    "    - `COVID_prevention_distancing`, `COVID_prevention_masks`: Indicate whether individuals practiced certain COVID prevention measures.\n",
    "  \n",
    "  - **Categorical Variables (to be transformed)**:\n",
    "    - `DEMO_gender`: We can transform gender categories into binary indicators if specific comparisons are needed.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15b0d4f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.228109\n",
      "         Iterations 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>Logit Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>       <td>str8fyre</td>     <th>  No. Observations:  </th>  <td>   800</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                 <td>Logit</td>      <th>  Df Residuals:      </th>  <td>   788</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>                 <td>MLE</td>       <th>  Df Model:          </th>  <td>    11</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>            <td>Thu, 14 Nov 2024</td> <th>  Pseudo R-squ.:     </th>  <td>0.05156</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                <td>17:54:44</td>     <th>  Log-Likelihood:    </th> <td> -182.49</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>converged:</th>             <td>True</td>       <th>  LL-Null:           </th> <td> -192.41</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>     <td>nonrobust</td>    <th>  LLR p-value:       </th>  <td>0.04757</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                      <td></td>                        <th>coef</th>     <th>std err</th>      <th>z</th>      <th>P>|z|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                <td>   -3.2644</td> <td>    0.714</td> <td>   -4.572</td> <td> 0.000</td> <td>   -4.664</td> <td>   -1.865</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                        <td>    4.3478</td> <td>    2.179</td> <td>    1.996</td> <td> 0.046</td> <td>    0.078</td> <td>    8.618</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 2\") == \"None\")[T.True]</th>         <td>    1.5432</td> <td>    0.853</td> <td>    1.810</td> <td> 0.070</td> <td>   -0.128</td> <td>    3.215</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>                       <td>   -0.0574</td> <td>    0.468</td> <td>   -0.123</td> <td> 0.902</td> <td>   -0.975</td> <td>    0.861</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>                       <td>   -0.6480</td> <td>    0.466</td> <td>   -1.390</td> <td> 0.164</td> <td>   -1.561</td> <td>    0.265</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>                       <td>   -0.8255</td> <td>    0.545</td> <td>   -1.516</td> <td> 0.130</td> <td>   -1.893</td> <td>    0.242</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>                       <td>   -0.5375</td> <td>    0.449</td> <td>   -1.198</td> <td> 0.231</td> <td>   -1.417</td> <td>    0.342</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>                       <td>    0.3213</td> <td>    0.477</td> <td>    0.673</td> <td> 0.501</td> <td>   -0.614</td> <td>    1.257</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                   <td>    0.0172</td> <td>    0.006</td> <td>    3.086</td> <td> 0.002</td> <td>    0.006</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                 <td>   -0.0365</td> <td>    0.019</td> <td>   -1.884</td> <td> 0.060</td> <td>   -0.074</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                  <td>   -0.0098</td> <td>    0.008</td> <td>   -1.247</td> <td> 0.213</td> <td>   -0.025</td> <td>    0.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:I(Q(\"Type 2\") == \"None\")[T.True]</th> <td>   -0.0197</td> <td>    0.012</td> <td>   -1.651</td> <td> 0.099</td> <td>   -0.043</td> <td>    0.004</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                           &     str8fyre     & \\textbf{  No. Observations:  } &      800    \\\\\n",
       "\\textbf{Model:}                                   &      Logit       & \\textbf{  Df Residuals:      } &      788    \\\\\n",
       "\\textbf{Method:}                                  &       MLE        & \\textbf{  Df Model:          } &       11    \\\\\n",
       "\\textbf{Date:}                                    & Thu, 14 Nov 2024 & \\textbf{  Pseudo R-squ.:     } &  0.05156    \\\\\n",
       "\\textbf{Time:}                                    &     17:54:44     & \\textbf{  Log-Likelihood:    } &   -182.49   \\\\\n",
       "\\textbf{converged:}                               &       True       & \\textbf{  LL-Null:           } &   -192.41   \\\\\n",
       "\\textbf{Covariance Type:}                         &    nonrobust     & \\textbf{  LLR p-value:       } &  0.04757    \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                  & \\textbf{coef} & \\textbf{std err} & \\textbf{z} & \\textbf{P$> |$z$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                &      -3.2644  &        0.714     &    -4.572  &         0.000        &       -4.664    &       -1.865     \\\\\n",
       "\\textbf{Legendary[T.True]}                        &       4.3478  &        2.179     &     1.996  &         0.046        &        0.078    &        8.618     \\\\\n",
       "\\textbf{I(Q(\"Type 2\") == \"None\")[T.True]}         &       1.5432  &        0.853     &     1.810  &         0.070        &       -0.128    &        3.215     \\\\\n",
       "\\textbf{C(Generation)[T.2]}                       &      -0.0574  &        0.468     &    -0.123  &         0.902        &       -0.975    &        0.861     \\\\\n",
       "\\textbf{C(Generation)[T.3]}                       &      -0.6480  &        0.466     &    -1.390  &         0.164        &       -1.561    &        0.265     \\\\\n",
       "\\textbf{C(Generation)[T.4]}                       &      -0.8255  &        0.545     &    -1.516  &         0.130        &       -1.893    &        0.242     \\\\\n",
       "\\textbf{C(Generation)[T.5]}                       &      -0.5375  &        0.449     &    -1.198  &         0.231        &       -1.417    &        0.342     \\\\\n",
       "\\textbf{C(Generation)[T.6]}                       &       0.3213  &        0.477     &     0.673  &         0.501        &       -0.614    &        1.257     \\\\\n",
       "\\textbf{Attack}                                   &       0.0172  &        0.006     &     3.086  &         0.002        &        0.006    &        0.028     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                 &      -0.0365  &        0.019     &    -1.884  &         0.060        &       -0.074    &        0.001     \\\\\n",
       "\\textbf{Defense}                                  &      -0.0098  &        0.008     &    -1.247  &         0.213        &       -0.025    &        0.006     \\\\\n",
       "\\textbf{Defense:I(Q(\"Type 2\") == \"None\")[T.True]} &      -0.0197  &        0.012     &    -1.651  &         0.099        &       -0.043    &        0.004     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{Logit Regression Results}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                           Logit Regression Results                           \n",
       "==============================================================================\n",
       "Dep. Variable:               str8fyre   No. Observations:                  800\n",
       "Model:                          Logit   Df Residuals:                      788\n",
       "Method:                           MLE   Df Model:                           11\n",
       "Date:                Thu, 14 Nov 2024   Pseudo R-squ.:                 0.05156\n",
       "Time:                        17:54:44   Log-Likelihood:                -182.49\n",
       "converged:                       True   LL-Null:                       -192.41\n",
       "Covariance Type:            nonrobust   LLR p-value:                   0.04757\n",
       "============================================================================================================\n",
       "                                               coef    std err          z      P>|z|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                   -3.2644      0.714     -4.572      0.000      -4.664      -1.865\n",
       "Legendary[T.True]                            4.3478      2.179      1.996      0.046       0.078       8.618\n",
       "I(Q(\"Type 2\") == \"None\")[T.True]             1.5432      0.853      1.810      0.070      -0.128       3.215\n",
       "C(Generation)[T.2]                          -0.0574      0.468     -0.123      0.902      -0.975       0.861\n",
       "C(Generation)[T.3]                          -0.6480      0.466     -1.390      0.164      -1.561       0.265\n",
       "C(Generation)[T.4]                          -0.8255      0.545     -1.516      0.130      -1.893       0.242\n",
       "C(Generation)[T.5]                          -0.5375      0.449     -1.198      0.231      -1.417       0.342\n",
       "C(Generation)[T.6]                           0.3213      0.477      0.673      0.501      -0.614       1.257\n",
       "Attack                                       0.0172      0.006      3.086      0.002       0.006       0.028\n",
       "Attack:Legendary[T.True]                    -0.0365      0.019     -1.884      0.060      -0.074       0.001\n",
       "Defense                                     -0.0098      0.008     -1.247      0.213      -0.025       0.006\n",
       "Defense:I(Q(\"Type 2\") == \"None\")[T.True]    -0.0197      0.012     -1.651      0.099      -0.043       0.004\n",
       "============================================================================================================\n",
       "\"\"\""
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "pokeaman = pd.read_csv(url).fillna('None')\n",
    "\n",
    "pokeaman['str8fyre'] = (pokeaman['Type 1']=='Fire').astype(int)\n",
    "linear_model_specification_formula = \\\n",
    "'str8fyre ~ Attack*Legendary + Defense*I(Q(\"Type 2\")==\"None\") + C(Generation)'\n",
    "log_reg_fit = smf.logit(linear_model_specification_formula, data=pokeaman).fit()\n",
    "log_reg_fit.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f6b2c127",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization terminated successfully.\n",
      "         Current function value: 0.000000\n",
      "         Iterations: 1\n",
      "         Function evaluations: 2\n",
      "         Gradient evaluations: 2\n",
      "                           Logit Regression Results                           \n",
      "==============================================================================\n",
      "Dep. Variable:       COVID_vaccinated   No. Observations:                 8758\n",
      "Model:                          Logit   Df Residuals:                     8755\n",
      "Method:                           MLE   Df Model:                            2\n",
      "Date:                Thu, 14 Nov 2024   Pseudo R-squ.:                     inf\n",
      "Time:                        17:54:47   Log-Likelihood:            -2.5110e-06\n",
      "converged:                       True   LL-Null:                        0.0000\n",
      "Covariance Type:            nonrobust   LLR p-value:                     1.000\n",
      "===============================================================================================\n",
      "                                  coef    std err          z      P>|z|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------\n",
      "Intercept                      -0.0215        nan        nan        nan         nan         nan\n",
      "DEMO_age                       -1.0010        nan        nan        nan         nan         nan\n",
      "WELLNESS_life_satisfaction     -0.1327        nan        nan        nan         nan         nan\n",
      "COVID_prevention_distancing          0        nan        nan        nan         nan         nan\n",
      "COVID_prevention_masks               0        nan        nan        nan         nan         nan\n",
      "===============================================================================================\n",
      "\n",
      "Complete Separation: The results show that there iscomplete separation or perfect prediction.\n",
      "In this case the Maximum Likelihood Estimator does not exist and the parameters\n",
      "are not identified.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.11/site-packages/statsmodels/base/model.py:595: HessianInversionWarning: Inverting hessian failed, no bse or cov_params available\n",
      "  warnings.warn('Inverting hessian failed, no bse or cov_params '\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:227: PerfectSeparationWarning: Perfect separation or prediction detected, parameter may not be identified\n",
      "  warnings.warn(msg, category=PerfectSeparationWarning)\n",
      "/opt/conda/lib/python3.11/site-packages/statsmodels/discrete/discrete_model.py:4465: RuntimeWarning: divide by zero encountered in scalar divide\n",
      "  return 1 - self.llf/self.llnull\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "# Load the dataset directly from the URL\n",
    "url = \"https://raw.githubusercontent.com/pointOfive/stat130chat130/refs/heads/main/CP/CSCS_data_anon.csv\"\n",
    "cscs_data = pd.read_csv(url, low_memory=False)\n",
    "\n",
    "# Convert relevant columns to binary or numeric as needed\n",
    "cscs_data['COVID_vaccinated'] = (cscs_data['COVID_vaccinated'] == 'Yes').astype(int)  # Binary outcome\n",
    "cscs_data['COVID_prevention_distancing'] = (cscs_data['COVID_prevention_distancing'] == 'Yes').astype(int)\n",
    "cscs_data['COVID_prevention_masks'] = (cscs_data['COVID_prevention_masks'] == 'Yes').astype(int)\n",
    "\n",
    "# Specify the logistic regression model formula\n",
    "formula = 'COVID_vaccinated ~ DEMO_age + WELLNESS_life_satisfaction + COVID_prevention_distancing + COVID_prevention_masks'\n",
    "\n",
    "# Fit the logistic regression model with increased iterations and a different optimization method\n",
    "log_reg_model = smf.logit(formula, data=cscs_data).fit(maxiter=100, method='bfgs')\n",
    "\n",
    "# Output model summary\n",
    "print(log_reg_model.summary())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e69df28",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93ddaf98",
   "metadata": {},
   "source": [
    "Here’s a summary of our discussion about logistic regression and model building for your project with the Canadian Social Connection Survey (CSCS) data:\n",
    "\n",
    "---\n",
    "\n",
    "### 1. **Introduction to Logistic Regression and Model Types**:\n",
    "   - We discussed that **logistic regression** is the preferred method when the **outcome variable** is binary (e.g., Yes/No, 0/1). This type of regression models the **probability** that an input belongs to a particular class, transforming a linear equation output into a probability through a **sigmoid function**.\n",
    "   - I explained that **logistic regression** differs from multiple linear regression because it operates on log-odds, not direct values, and that interpreting log-odds can be challenging, but it essentially describes how predictor variables influence the probability of the outcome.\n",
    "   \n",
    "### 2. **Additive vs. Synergistic Models**:\n",
    "   - An **additive model** treats each predictor independently, combining them in a simple linear form without interactions. In this context, changes in one predictor don’t depend on changes in another.\n",
    "   - A **synergistic (interaction) model** includes interaction terms, capturing how the effect of one predictor on the outcome might change based on the level of another predictor.\n",
    "\n",
    "### 3. **Preprocessing the Data**:\n",
    "   - We covered the steps for **data preparation**:\n",
    "      - Load and clean the CSCS dataset.\n",
    "      - Convert categorical variables into binary (0/1) if necessary, either through direct conversion or one-hot encoding, allowing categorical predictors to fit into a logistic regression framework.\n",
    "   \n",
    "### 4. **Implementing Logistic Regression with `statsmodels`**:\n",
    "   - We explored how to use Python’s `statsmodels.formula.api` (smf) for **logistic regression modeling**:\n",
    "      - Defined an **additive model** (`Outcome ~ Predictor1 + Predictor2`) using continuous, binary, and categorical predictors.\n",
    "      - Defined an **interaction model** (`Outcome ~ Predictor1 * Predictor2`), including an interaction term to see if it significantly impacts the model.\n",
    "      - I provided example code to run both additive and interaction models, fit them, and interpret the resulting `.summary()` output.\n",
    "\n",
    "### 5. **Interpreting Results**:\n",
    "   - In logistic regression, **coefficients** are in terms of **log-odds**. For interpretation, we discussed:\n",
    "      - Positive coefficients indicate an increase in the odds of the outcome, while negative coefficients indicate a decrease.\n",
    "      - P-values from the model summary indicate whether each predictor is statistically significant.\n",
    "\n",
    "### 6. **Visualizing Predictions**:\n",
    "   - Because logistic regression outputs probabilities, I suggested using **Plotly** to create scatter plots of predicted probabilities against a continuous predictor. Although logistic regression does not naturally yield “best fit lines,” plotting predicted probabilities helps visualize the relationship between predictors and the outcome.\n",
    "   - I provided sample code for visualizing both the additive and interaction models’ predictions.\n",
    "\n",
    "### 7. **Binary vs. Non-Binary Outcomes**:\n",
    "   - I clarified that logistic regression is specifically for binary outcomes. For **non-binary outcomes**:\n",
    "      - **Multinomial logistic regression** would be appropriate for categorical outcomes with more than two classes.\n",
    "      - **Ordinal logistic regression** applies to ordered categorical outcomes.\n",
    "      - **Linear regression** applies if the outcome variable is continuous.\n",
    "\n",
    "---\n",
    "\n",
    "This summary reflects our discussions on logistic regression concepts, data preparation, model building, and interpretation techniques tailored to your CSCS data project. Let me know if there’s anything you’d like me to add or clarify for your submission!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a3c8c7",
   "metadata": {},
   "source": [
    "### Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d100de11",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/6734df46-6ac8-8010-a7a9-60917e7e3d71"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39dacae2",
   "metadata": {},
   "source": [
    "# Question 4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d107b7",
   "metadata": {},
   "source": [
    "\n",
    "1. **R-squared (Explained Variance)**:\n",
    "   - The **R-squared** value indicates how much of the overall variability in the outcome variable \\( y \\) is explained by the model’s predictors. \n",
    "   - A low R-squared (e.g., 17.6%) means that the predictors, taken as a whole, explain only a small portion of the variation in \\( y \\). In other words, the model does not capture all the factors that influence the outcome, leaving a lot of variability unexplained.\n",
    "   - This could happen if important factors are missing from the model or if the relationship between the predictors and the outcome is complex and not fully captured by the model.\n",
    "\n",
    "2. **Coefficient Significance and p-values**:\n",
    "   - Even with a low R-squared, the model can still produce **statistically significant coefficients**. When a coefficient has a small p-value (e.g., \\( p < 0.001 \\)), this suggests there is strong evidence against the null hypothesis that the predictor has no effect on \\( y \\) when all other predictors are held constant.\n",
    "   - This means that **each predictor might individually be associated with changes in the outcome variable**, and we have strong evidence that these effects are not due to random chance. However, this does not guarantee that the combined effect of these predictors explains a large portion of the variability in \\( y \\), especially if \\( y \\) depends heavily on other factors not included in the model.\n",
    "\n",
    "### Why the Contradiction Is Only Apparent\n",
    "The **p-values for individual coefficients** and the **R-squared** value address two different questions:\n",
    "- **R-squared** reflects the proportion of total variability in \\( y \\) explained by the entire model.\n",
    "- **P-values** for coefficients reflect the strength of the evidence for an individual predictor's effect on \\( y \\) after accounting for other predictors.\n",
    "\n",
    "It’s possible for a model to have significant predictors (low p-values) while still having a low R-squared if:\n",
    "- The predictors only explain a small part of the variability in the outcome.\n",
    "- The variability in the outcome is driven by other factors not included in the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "28791003",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Bulbasaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>45</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>65</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Ivysaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>60</td>\n",
       "      <td>62</td>\n",
       "      <td>63</td>\n",
       "      <td>80</td>\n",
       "      <td>80</td>\n",
       "      <td>60</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>82</td>\n",
       "      <td>83</td>\n",
       "      <td>100</td>\n",
       "      <td>100</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>VenusaurMega Venusaur</td>\n",
       "      <td>Grass</td>\n",
       "      <td>Poison</td>\n",
       "      <td>80</td>\n",
       "      <td>100</td>\n",
       "      <td>123</td>\n",
       "      <td>122</td>\n",
       "      <td>120</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Charmander</td>\n",
       "      <td>Fire</td>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "      <td>52</td>\n",
       "      <td>43</td>\n",
       "      <td>60</td>\n",
       "      <td>50</td>\n",
       "      <td>65</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>795</th>\n",
       "      <td>719</td>\n",
       "      <td>Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>100</td>\n",
       "      <td>150</td>\n",
       "      <td>50</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>796</th>\n",
       "      <td>719</td>\n",
       "      <td>DiancieMega Diancie</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Fairy</td>\n",
       "      <td>50</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>160</td>\n",
       "      <td>110</td>\n",
       "      <td>110</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Unbound</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Dark</td>\n",
       "      <td>80</td>\n",
       "      <td>160</td>\n",
       "      <td>60</td>\n",
       "      <td>170</td>\n",
       "      <td>130</td>\n",
       "      <td>80</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>799</th>\n",
       "      <td>721</td>\n",
       "      <td>Volcanion</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Water</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>120</td>\n",
       "      <td>130</td>\n",
       "      <td>90</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                   Name   Type 1  Type 2  HP  Attack  Defense  \\\n",
       "0      1              Bulbasaur    Grass  Poison  45      49       49   \n",
       "1      2                Ivysaur    Grass  Poison  60      62       63   \n",
       "2      3               Venusaur    Grass  Poison  80      82       83   \n",
       "3      3  VenusaurMega Venusaur    Grass  Poison  80     100      123   \n",
       "4      4             Charmander     Fire     NaN  39      52       43   \n",
       "..   ...                    ...      ...     ...  ..     ...      ...   \n",
       "795  719                Diancie     Rock   Fairy  50     100      150   \n",
       "796  719    DiancieMega Diancie     Rock   Fairy  50     160      110   \n",
       "797  720    HoopaHoopa Confined  Psychic   Ghost  80     110       60   \n",
       "798  720     HoopaHoopa Unbound  Psychic    Dark  80     160       60   \n",
       "799  721              Volcanion     Fire   Water  80     110      120   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "0         65       65     45           1      False  \n",
       "1         80       80     60           1      False  \n",
       "2        100      100     80           1      False  \n",
       "3        122      120     80           1      False  \n",
       "4         60       50     65           1      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "795      100      150     50           6       True  \n",
       "796      160      110    110           6       True  \n",
       "797      150      130     70           6       True  \n",
       "798      170      130     80           6       True  \n",
       "799      130       90     70           6       True  \n",
       "\n",
       "[800 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/KeithGalli/pandas/master/pokemon_data.csv\"\n",
    "# fail https://github.com/KeithGalli/pandas/blob/master/pokemon_data.csv\n",
    "pokeaman = pd.read_csv(url) \n",
    "pokeaman"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c031687",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   15.27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>3.50e-27</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:54:47</td>     <th>  Log-Likelihood:    </th> <td> -3649.4</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   800</td>      <th>  AIC:               </th> <td>   7323.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   788</td>      <th>  BIC:               </th> <td>   7379.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    11</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                 <td></td>                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                       <td>   26.8971</td> <td>    5.246</td> <td>    5.127</td> <td> 0.000</td> <td>   16.599</td> <td>   37.195</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>              <td>   20.0449</td> <td>    7.821</td> <td>    2.563</td> <td> 0.011</td> <td>    4.692</td> <td>   35.398</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>              <td>   21.3662</td> <td>    6.998</td> <td>    3.053</td> <td> 0.002</td> <td>    7.629</td> <td>   35.103</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>              <td>   31.9575</td> <td>    8.235</td> <td>    3.881</td> <td> 0.000</td> <td>   15.793</td> <td>   48.122</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>              <td>    9.4926</td> <td>    7.883</td> <td>    1.204</td> <td> 0.229</td> <td>   -5.982</td> <td>   24.968</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>              <td>   22.2693</td> <td>    8.709</td> <td>    2.557</td> <td> 0.011</td> <td>    5.173</td> <td>   39.366</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                    <td>    0.5634</td> <td>    0.071</td> <td>    7.906</td> <td> 0.000</td> <td>    0.423</td> <td>    0.703</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.2]</th> <td>   -0.2350</td> <td>    0.101</td> <td>   -2.316</td> <td> 0.021</td> <td>   -0.434</td> <td>   -0.036</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.3]</th> <td>   -0.3067</td> <td>    0.093</td> <td>   -3.300</td> <td> 0.001</td> <td>   -0.489</td> <td>   -0.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.4]</th> <td>   -0.3790</td> <td>    0.105</td> <td>   -3.600</td> <td> 0.000</td> <td>   -0.586</td> <td>   -0.172</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.5]</th> <td>   -0.0484</td> <td>    0.108</td> <td>   -0.447</td> <td> 0.655</td> <td>   -0.261</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):C(Generation)[T.6]</th> <td>   -0.3083</td> <td>    0.112</td> <td>   -2.756</td> <td> 0.006</td> <td>   -0.528</td> <td>   -0.089</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>337.229</td> <th>  Durbin-Watson:     </th> <td>   1.505</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2871.522</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.684</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>11.649</td>  <th>  Cond. No.          </th> <td>1.40e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.4e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                  &        HP        & \\textbf{  R-squared:         } &     0.176   \\\\\n",
       "\\textbf{Model:}                          &       OLS        & \\textbf{  Adj. R-squared:    } &     0.164   \\\\\n",
       "\\textbf{Method:}                         &  Least Squares   & \\textbf{  F-statistic:       } &     15.27   \\\\\n",
       "\\textbf{Date:}                           & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  3.50e-27   \\\\\n",
       "\\textbf{Time:}                           &     17:54:47     & \\textbf{  Log-Likelihood:    } &   -3649.4   \\\\\n",
       "\\textbf{No. Observations:}               &         800      & \\textbf{  AIC:               } &     7323.   \\\\\n",
       "\\textbf{Df Residuals:}                   &         788      & \\textbf{  BIC:               } &     7379.   \\\\\n",
       "\\textbf{Df Model:}                       &          11      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                         & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                       &      26.8971  &        5.246     &     5.127  &         0.000        &       16.599    &       37.195     \\\\\n",
       "\\textbf{C(Generation)[T.2]}              &      20.0449  &        7.821     &     2.563  &         0.011        &        4.692    &       35.398     \\\\\n",
       "\\textbf{C(Generation)[T.3]}              &      21.3662  &        6.998     &     3.053  &         0.002        &        7.629    &       35.103     \\\\\n",
       "\\textbf{C(Generation)[T.4]}              &      31.9575  &        8.235     &     3.881  &         0.000        &       15.793    &       48.122     \\\\\n",
       "\\textbf{C(Generation)[T.5]}              &       9.4926  &        7.883     &     1.204  &         0.229        &       -5.982    &       24.968     \\\\\n",
       "\\textbf{C(Generation)[T.6]}              &      22.2693  &        8.709     &     2.557  &         0.011        &        5.173    &       39.366     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                    &       0.5634  &        0.071     &     7.906  &         0.000        &        0.423    &        0.703     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.2]} &      -0.2350  &        0.101     &    -2.316  &         0.021        &       -0.434    &       -0.036     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.3]} &      -0.3067  &        0.093     &    -3.300  &         0.001        &       -0.489    &       -0.124     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.4]} &      -0.3790  &        0.105     &    -3.600  &         0.000        &       -0.586    &       -0.172     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.5]} &      -0.0484  &        0.108     &    -0.447  &         0.655        &       -0.261    &        0.164     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):C(Generation)[T.6]} &      -0.3083  &        0.112     &    -2.756  &         0.006        &       -0.528    &       -0.089     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 337.229 & \\textbf{  Durbin-Watson:     } &    1.505  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2871.522  \\\\\n",
       "\\textbf{Skew:}          &   1.684 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  11.649 & \\textbf{  Cond. No.          } & 1.40e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.4e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.176\n",
       "Model:                            OLS   Adj. R-squared:                  0.164\n",
       "Method:                 Least Squares   F-statistic:                     15.27\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           3.50e-27\n",
       "Time:                        17:54:47   Log-Likelihood:                -3649.4\n",
       "No. Observations:                 800   AIC:                             7323.\n",
       "Df Residuals:                     788   BIC:                             7379.\n",
       "Df Model:                          11                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "===================================================================================================\n",
       "                                      coef    std err          t      P>|t|      [0.025      0.975]\n",
       "---------------------------------------------------------------------------------------------------\n",
       "Intercept                          26.8971      5.246      5.127      0.000      16.599      37.195\n",
       "C(Generation)[T.2]                 20.0449      7.821      2.563      0.011       4.692      35.398\n",
       "C(Generation)[T.3]                 21.3662      6.998      3.053      0.002       7.629      35.103\n",
       "C(Generation)[T.4]                 31.9575      8.235      3.881      0.000      15.793      48.122\n",
       "C(Generation)[T.5]                  9.4926      7.883      1.204      0.229      -5.982      24.968\n",
       "C(Generation)[T.6]                 22.2693      8.709      2.557      0.011       5.173      39.366\n",
       "Q(\"Sp. Def\")                        0.5634      0.071      7.906      0.000       0.423       0.703\n",
       "Q(\"Sp. Def\"):C(Generation)[T.2]    -0.2350      0.101     -2.316      0.021      -0.434      -0.036\n",
       "Q(\"Sp. Def\"):C(Generation)[T.3]    -0.3067      0.093     -3.300      0.001      -0.489      -0.124\n",
       "Q(\"Sp. Def\"):C(Generation)[T.4]    -0.3790      0.105     -3.600      0.000      -0.586      -0.172\n",
       "Q(\"Sp. Def\"):C(Generation)[T.5]    -0.0484      0.108     -0.447      0.655      -0.261       0.164\n",
       "Q(\"Sp. Def\"):C(Generation)[T.6]    -0.3083      0.112     -2.756      0.006      -0.528      -0.089\n",
       "==============================================================================\n",
       "Omnibus:                      337.229   Durbin-Watson:                   1.505\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2871.522\n",
       "Skew:                           1.684   Prob(JB):                         0.00\n",
       "Kurtosis:                      11.649   Cond. No.                     1.40e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.4e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import statsmodels.formula.api as smf\n",
    "\n",
    "model1_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation)', data=pokeaman)\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") + C(Generation) + Q(\"Sp. Def\"):C(Generation)', data=pokeaman)\n",
    "#Q(\"Sp. Def\"):C(Generation). This term models the interaction between Sp. Def and Generation\n",
    "model2_spec = smf.ols(formula='HP ~ Q(\"Sp. Def\") * C(Generation)', data=pokeaman)\n",
    "# Using Q(\"Sp. Def\") * C(Generation) is shorthand for Q(\"Sp. Def\") + C(Generation) + Q(\"Sp. Def\"):C(Generation)\n",
    "\n",
    "model2_fit = model2_spec.fit()\n",
    "model2_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8d2aabc",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14db2566",
   "metadata": {},
   "source": [
    "Here's a summary of our exchanges in this session:\n",
    "\n",
    "---\n",
    "\n",
    "### Linear Regression Concepts and Interpretation\n",
    "\n",
    "1. **Understanding R-squared and p-values**:\n",
    "   - **R-squared**: We discussed that R-squared measures the proportion of variability in the outcome variable \\( y \\) that the model explains. For example, an R-squared of 17.6% indicates that the model only explains 17.6% of the total variability in \\( y \\), suggesting that additional factors might influence the outcome that aren’t captured in the model.\n",
    "   - **p-values and coefficient significance**: We examined how p-values are used to test the null hypothesis for each coefficient, specifically testing whether each predictor has a statistically significant effect on the outcome variable. We noted that even with a low R-squared, individual coefficients can still have small p-values, indicating significant relationships. Thus, R-squared and p-values address different aspects of the model’s explanatory power and significance.\n",
    "\n",
    "2. **Clarifying Observed Data and Predictions**:\n",
    "   - **Observed data vs. predicted data**: We clarified that “observed data” refers to the real-world (or actual) values recorded for the outcome variable \\( y \\). In contrast, **predicted data** (denoted \\( \\hat{y} \\)) represents values calculated by the model based on the estimated coefficients.\n",
    "\n",
    "3. **Code Explanation**:\n",
    "   - We analyzed a Python code snippet for fitting OLS regression models using `statsmodels`. The code included:\n",
    "     - Three model specifications, each predicting `HP` (Hit Points) as a function of `Sp. Def` (Special Defense) and `Generation`.\n",
    "     - Differences in model structure, such as using `Q(\"Sp. Def\")` to handle a space in the column name and `C(Generation)` to treat `Generation` as a categorical variable.\n",
    "     - Adding interaction terms to allow for the effect of `Sp. Def` on `HP` to vary by generation, showing how `Q(\"Sp. Def\") * C(Generation)` is shorthand for including both the main effects and their interaction.\n",
    "   - After specifying the models, the code fits the final model and generates a summary. This summary includes coefficient estimates, p-values for hypothesis testing, and R-squared values to assess the model's explanatory power.\n",
    "\n",
    "---\n",
    "\n",
    "This summary covers our discussion on interpreting R-squared, p-values, observed and predicted data, and the specific Python code for building and evaluating regression models. This provides a clear record of our interactions for your assignment. Let me know if you need further details or clarification."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc70d6af",
   "metadata": {},
   "source": [
    "### Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a833ddc",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/6734e4b8-90e8-8010-b606-5fb40de7e5ec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "104d25db",
   "metadata": {},
   "source": [
    "# Question 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "92c1ba53",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>#</th>\n",
       "      <th>Name</th>\n",
       "      <th>Type 1</th>\n",
       "      <th>Type 2</th>\n",
       "      <th>HP</th>\n",
       "      <th>Attack</th>\n",
       "      <th>Defense</th>\n",
       "      <th>Sp. Atk</th>\n",
       "      <th>Sp. Def</th>\n",
       "      <th>Speed</th>\n",
       "      <th>Generation</th>\n",
       "      <th>Legendary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>370</th>\n",
       "      <td>338</td>\n",
       "      <td>Solrock</td>\n",
       "      <td>Rock</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>70</td>\n",
       "      <td>95</td>\n",
       "      <td>85</td>\n",
       "      <td>55</td>\n",
       "      <td>65</td>\n",
       "      <td>70</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>Charizard</td>\n",
       "      <td>Fire</td>\n",
       "      <td>Flying</td>\n",
       "      <td>78</td>\n",
       "      <td>84</td>\n",
       "      <td>78</td>\n",
       "      <td>109</td>\n",
       "      <td>85</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>242</th>\n",
       "      <td>224</td>\n",
       "      <td>Octillery</td>\n",
       "      <td>Water</td>\n",
       "      <td>None</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>105</td>\n",
       "      <td>75</td>\n",
       "      <td>45</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>661</th>\n",
       "      <td>600</td>\n",
       "      <td>Klang</td>\n",
       "      <td>Steel</td>\n",
       "      <td>None</td>\n",
       "      <td>60</td>\n",
       "      <td>80</td>\n",
       "      <td>95</td>\n",
       "      <td>70</td>\n",
       "      <td>85</td>\n",
       "      <td>50</td>\n",
       "      <td>5</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>265</td>\n",
       "      <td>Wurmple</td>\n",
       "      <td>Bug</td>\n",
       "      <td>None</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>20</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522</th>\n",
       "      <td>471</td>\n",
       "      <td>Glaceon</td>\n",
       "      <td>Ice</td>\n",
       "      <td>None</td>\n",
       "      <td>65</td>\n",
       "      <td>60</td>\n",
       "      <td>110</td>\n",
       "      <td>130</td>\n",
       "      <td>95</td>\n",
       "      <td>65</td>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>243</th>\n",
       "      <td>225</td>\n",
       "      <td>Delibird</td>\n",
       "      <td>Ice</td>\n",
       "      <td>Flying</td>\n",
       "      <td>45</td>\n",
       "      <td>55</td>\n",
       "      <td>45</td>\n",
       "      <td>65</td>\n",
       "      <td>45</td>\n",
       "      <td>75</td>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>797</th>\n",
       "      <td>720</td>\n",
       "      <td>HoopaHoopa Confined</td>\n",
       "      <td>Psychic</td>\n",
       "      <td>Ghost</td>\n",
       "      <td>80</td>\n",
       "      <td>110</td>\n",
       "      <td>60</td>\n",
       "      <td>150</td>\n",
       "      <td>130</td>\n",
       "      <td>70</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>117</th>\n",
       "      <td>109</td>\n",
       "      <td>Koffing</td>\n",
       "      <td>Poison</td>\n",
       "      <td>None</td>\n",
       "      <td>40</td>\n",
       "      <td>65</td>\n",
       "      <td>95</td>\n",
       "      <td>60</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>409</th>\n",
       "      <td>373</td>\n",
       "      <td>SalamenceMega Salamence</td>\n",
       "      <td>Dragon</td>\n",
       "      <td>Flying</td>\n",
       "      <td>95</td>\n",
       "      <td>145</td>\n",
       "      <td>130</td>\n",
       "      <td>120</td>\n",
       "      <td>90</td>\n",
       "      <td>120</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>400 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       #                     Name   Type 1   Type 2  HP  Attack  Defense  \\\n",
       "370  338                  Solrock     Rock  Psychic  70      95       85   \n",
       "6      6                Charizard     Fire   Flying  78      84       78   \n",
       "242  224                Octillery    Water     None  75     105       75   \n",
       "661  600                    Klang    Steel     None  60      80       95   \n",
       "288  265                  Wurmple      Bug     None  45      45       35   \n",
       "..   ...                      ...      ...      ...  ..     ...      ...   \n",
       "522  471                  Glaceon      Ice     None  65      60      110   \n",
       "243  225                 Delibird      Ice   Flying  45      55       45   \n",
       "797  720      HoopaHoopa Confined  Psychic    Ghost  80     110       60   \n",
       "117  109                  Koffing   Poison     None  40      65       95   \n",
       "409  373  SalamenceMega Salamence   Dragon   Flying  95     145      130   \n",
       "\n",
       "     Sp. Atk  Sp. Def  Speed  Generation  Legendary  \n",
       "370       55       65     70           3      False  \n",
       "6        109       85    100           1      False  \n",
       "242      105       75     45           2      False  \n",
       "661       70       85     50           5      False  \n",
       "288       20       30     20           3      False  \n",
       "..       ...      ...    ...         ...        ...  \n",
       "522      130       95     65           4      False  \n",
       "243       65       45     75           2      False  \n",
       "797      150      130     70           6       True  \n",
       "117       60       45     35           1      False  \n",
       "409      120       90    120           3      False  \n",
       "\n",
       "[400 rows x 12 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "fifty_fifty_split_size = int(pokeaman.shape[0]*0.5)\n",
    "\n",
    "# Replace \"NaN\" (in the \"Type 2\" column with \"None\")\n",
    "pokeaman.fillna('None', inplace=True)\n",
    "\n",
    "np.random.seed(130)\n",
    "pokeaman_train,pokeaman_test = \\\n",
    "  train_test_split(pokeaman, train_size=fifty_fifty_split_size)\n",
    "pokeaman_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6277d51e",
   "metadata": {},
   "source": [
    "### Cell 1: Data Preparation\n",
    "1. **Data Splitting**: The code splits the `pokeaman` dataset into a training set (`pokeaman_train`) and a testing set (`pokeaman_test`) to allow for in-sample and out-of-sample testing.\n",
    "2. **Handling NaNs**: The `fillna('None')` function ensures that any missing values in the \"Type 2\" column are replaced, which is essential for consistency in the dataset.\n",
    "3. **Setting a Seed**: By setting `np.random.seed(130)`, the random operations (like the split) are reproducible, ensuring that the results are consistent across runs.\n",
    "\n",
    "This setup enables a clear division between data used to train the model (in-sample) and data reserved to evaluate it (out-of-sample), which is foundational for assessing model generalizability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "707e3831",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:54:47</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     17:54:47     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        17:54:47   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_spec3 = smf.ols(formula='HP ~ Attack + Defense', \n",
    "                      data=pokeaman_train)\n",
    "model3_fit = model_spec3.fit()\n",
    "model3_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab7b2454",
   "metadata": {},
   "source": [
    "### Cell 2: Fitting a Simple Model (Model 3)\n",
    "1. **Model Specification**: Specifies a simple linear model (Model 3) with `HP` as the dependent variable and `Attack` and `Defense` as predictors.\n",
    "2. **Model Fitting**: Fits the model using the training data (`pokeaman_train`).\n",
    "3. **Model Summary**: The `summary()` method provides a detailed statistical output, including R-squared, coefficients, and significance levels for each predictor, which gives insight into the model's fit to the training data.\n",
    "\n",
    "The R-squared from this summary will serve as the **in-sample R-squared** for Model 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "02f147aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.14771558304519894\n",
      "'Out of sample' R-squared: 0.21208501873920738\n"
     ]
    }
   ],
   "source": [
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model3)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92b849b2",
   "metadata": {},
   "source": [
    "### Cell 3: Calculating In-Sample and Out-of-Sample R-squared for Model 3\n",
    "```python\n",
    "yhat_model3 = model3_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model3_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y, yhat_model3)[0, 1]**2)\n",
    "```\n",
    "In this cell:\n",
    "1. **In-Sample R-squared**: The `model3_fit.rsquared` is the in-sample R-squared, indicating how well the model fits the training data.\n",
    "2. **Out-of-Sample Predictions**: The model predicts `HP` values for the test set (`pokeaman_test`) based on the learned relationship from the training data.\n",
    "3. **Out-of-Sample R-squared**: Calculating `np.corrcoef(y, yhat_model3)[0,1]**2` provides an out-of-sample R-squared by measuring the squared correlation between the observed `HP` values in the test set and the model’s predictions.\n",
    "\n",
    "The comparison of in-sample vs. out-of-sample R-squared helps assess whether Model 3 generalizes well. If the out-of-sample R-squared is significantly lower, it may indicate overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "71819333",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.467</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.369</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.764</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.23e-21</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:54:47</td>     <th>  Log-Likelihood:    </th> <td> -1738.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3603.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   337</td>      <th>  BIC:               </th> <td>   3855.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    62</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                                  <td></td>                                    <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                                        <td>  521.5715</td> <td>  130.273</td> <td>    4.004</td> <td> 0.000</td> <td>  265.322</td> <td>  777.821</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>                                                <td>   -6.1179</td> <td>    2.846</td> <td>   -2.150</td> <td> 0.032</td> <td>  -11.716</td> <td>   -0.520</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                                           <td>   -8.1938</td> <td>    2.329</td> <td>   -3.518</td> <td> 0.000</td> <td>  -12.775</td> <td>   -3.612</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]</th>                                         <td>-1224.9610</td> <td>  545.105</td> <td>   -2.247</td> <td> 0.025</td> <td>-2297.199</td> <td> -152.723</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                                                          <td>   -6.1989</td> <td>    2.174</td> <td>   -2.851</td> <td> 0.005</td> <td>  -10.475</td> <td>   -1.923</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]</th>                                        <td> -102.4030</td> <td>   96.565</td> <td>   -1.060</td> <td> 0.290</td> <td> -292.350</td> <td>   87.544</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense</th>                                                   <td>    0.0985</td> <td>    0.033</td> <td>    2.982</td> <td> 0.003</td> <td>    0.034</td> <td>    0.164</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]</th>                                 <td>   14.6361</td> <td>    6.267</td> <td>    2.336</td> <td> 0.020</td> <td>    2.310</td> <td>   26.963</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                                            <td>   -7.2261</td> <td>    2.178</td> <td>   -3.318</td> <td> 0.001</td> <td>  -11.511</td> <td>   -2.942</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]</th>                                          <td>  704.8798</td> <td>  337.855</td> <td>    2.086</td> <td> 0.038</td> <td>   40.309</td> <td> 1369.450</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                                                     <td>    0.1264</td> <td>    0.038</td> <td>    3.351</td> <td> 0.001</td> <td>    0.052</td> <td>    0.201</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]</th>                                   <td>    5.8648</td> <td>    2.692</td> <td>    2.179</td> <td> 0.030</td> <td>    0.570</td> <td>   11.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed</th>                                                    <td>    0.1026</td> <td>    0.039</td> <td>    2.634</td> <td> 0.009</td> <td>    0.026</td> <td>    0.179</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]</th>                                  <td>   -6.9266</td> <td>    3.465</td> <td>   -1.999</td> <td> 0.046</td> <td>  -13.742</td> <td>   -0.111</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed</th>                                             <td>   -0.0016</td> <td>    0.001</td> <td>   -2.837</td> <td> 0.005</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]</th>                           <td>   -0.0743</td> <td>    0.030</td> <td>   -2.477</td> <td> 0.014</td> <td>   -0.133</td> <td>   -0.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                                                     <td>   -5.3982</td> <td>    1.938</td> <td>   -2.785</td> <td> 0.006</td> <td>   -9.211</td> <td>   -1.586</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\")</th>                                   <td> -282.2496</td> <td>  126.835</td> <td>   -2.225</td> <td> 0.027</td> <td> -531.738</td> <td>  -32.761</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                                              <td>    0.1094</td> <td>    0.034</td> <td>    3.233</td> <td> 0.001</td> <td>    0.043</td> <td>    0.176</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\")</th>                            <td>   12.6503</td> <td>    5.851</td> <td>    2.162</td> <td> 0.031</td> <td>    1.141</td> <td>   24.160</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\")</th>                                             <td>    0.0628</td> <td>    0.028</td> <td>    2.247</td> <td> 0.025</td> <td>    0.008</td> <td>    0.118</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                           <td>    3.3949</td> <td>    1.783</td> <td>    1.904</td> <td> 0.058</td> <td>   -0.112</td> <td>    6.902</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\")</th>                                      <td>   -0.0012</td> <td>    0.000</td> <td>   -2.730</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")</th>                    <td>   -0.1456</td> <td>    0.065</td> <td>   -2.253</td> <td> 0.025</td> <td>   -0.273</td> <td>   -0.018</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                                               <td>    0.0624</td> <td>    0.031</td> <td>    2.027</td> <td> 0.043</td> <td>    0.002</td> <td>    0.123</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                             <td>   -3.2219</td> <td>    1.983</td> <td>   -1.625</td> <td> 0.105</td> <td>   -7.122</td> <td>    0.678</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>                                        <td>   -0.0014</td> <td>    0.001</td> <td>   -2.732</td> <td> 0.007</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                      <td>   -0.0695</td> <td>    0.033</td> <td>   -2.100</td> <td> 0.036</td> <td>   -0.135</td> <td>   -0.004</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\")</th>                                       <td>   -0.0008</td> <td>    0.000</td> <td>   -1.743</td> <td> 0.082</td> <td>   -0.002</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>                     <td>    0.0334</td> <td>    0.021</td> <td>    1.569</td> <td> 0.117</td> <td>   -0.008</td> <td>    0.075</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\")</th>                                <td> 1.629e-05</td> <td> 6.92e-06</td> <td>    2.355</td> <td> 0.019</td> <td> 2.68e-06</td> <td> 2.99e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")</th>              <td>    0.0008</td> <td>    0.000</td> <td>    2.433</td> <td> 0.015</td> <td>    0.000</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                                                     <td>   -8.3636</td> <td>    2.346</td> <td>   -3.565</td> <td> 0.000</td> <td>  -12.978</td> <td>   -3.749</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Atk\")</th>                                   <td>  850.5436</td> <td>  385.064</td> <td>    2.209</td> <td> 0.028</td> <td>   93.112</td> <td> 1607.975</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                                              <td>    0.1388</td> <td>    0.040</td> <td>    3.500</td> <td> 0.001</td> <td>    0.061</td> <td>    0.217</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Atk\")</th>                            <td>    2.1809</td> <td>    1.136</td> <td>    1.920</td> <td> 0.056</td> <td>   -0.054</td> <td>    4.416</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Atk\")</th>                                             <td>    0.0831</td> <td>    0.038</td> <td>    2.162</td> <td> 0.031</td> <td>    0.007</td> <td>    0.159</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                           <td>   -7.3121</td> <td>    3.376</td> <td>   -2.166</td> <td> 0.031</td> <td>  -13.953</td> <td>   -0.671</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Atk\")</th>                                      <td>   -0.0014</td> <td>    0.001</td> <td>   -2.480</td> <td> 0.014</td> <td>   -0.003</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")</th>                    <td>   -0.0434</td> <td>    0.022</td> <td>   -2.010</td> <td> 0.045</td> <td>   -0.086</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                                               <td>    0.1011</td> <td>    0.035</td> <td>    2.872</td> <td> 0.004</td> <td>    0.032</td> <td>    0.170</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                             <td>  -12.6343</td> <td>    5.613</td> <td>   -2.251</td> <td> 0.025</td> <td>  -23.674</td> <td>   -1.594</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>                                        <td>   -0.0018</td> <td>    0.001</td> <td>   -3.102</td> <td> 0.002</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                      <td>    0.0151</td> <td>    0.009</td> <td>    1.609</td> <td> 0.109</td> <td>   -0.003</td> <td>    0.034</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Atk\")</th>                                       <td>   -0.0012</td> <td>    0.001</td> <td>   -1.860</td> <td> 0.064</td> <td>   -0.002</td> <td> 6.62e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>                     <td>    0.1210</td> <td>    0.054</td> <td>    2.260</td> <td> 0.024</td> <td>    0.016</td> <td>    0.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Atk\")</th>                                <td> 2.125e-05</td> <td>  9.1e-06</td> <td>    2.334</td> <td> 0.020</td> <td> 3.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")</th>              <td> 6.438e-06</td> <td> 7.69e-05</td> <td>    0.084</td> <td> 0.933</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                        <td>    0.1265</td> <td>    0.033</td> <td>    3.821</td> <td> 0.000</td> <td>    0.061</td> <td>    0.192</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                      <td>   -5.0544</td> <td>    2.506</td> <td>   -2.017</td> <td> 0.044</td> <td>   -9.983</td> <td>   -0.126</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                 <td>   -0.0021</td> <td>    0.001</td> <td>   -3.606</td> <td> 0.000</td> <td>   -0.003</td> <td>   -0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>               <td>   -0.0346</td> <td>    0.017</td> <td>   -1.992</td> <td> 0.047</td> <td>   -0.069</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                <td>   -0.0012</td> <td>    0.000</td> <td>   -2.406</td> <td> 0.017</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0446</td> <td>    0.025</td> <td>    1.794</td> <td> 0.074</td> <td>   -0.004</td> <td>    0.093</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                         <td> 1.973e-05</td> <td> 7.28e-06</td> <td>    2.710</td> <td> 0.007</td> <td> 5.41e-06</td> <td>  3.4e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>    0.0005</td> <td>    0.000</td> <td>    1.957</td> <td> 0.051</td> <td>-2.56e-06</td> <td>    0.001</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                                  <td>   -0.0013</td> <td>    0.000</td> <td>   -2.740</td> <td> 0.006</td> <td>   -0.002</td> <td>   -0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                <td>    0.0841</td> <td>    0.040</td> <td>    2.125</td> <td> 0.034</td> <td>    0.006</td> <td>    0.162</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                           <td> 2.379e-05</td> <td> 7.85e-06</td> <td>    3.030</td> <td> 0.003</td> <td> 8.34e-06</td> <td> 3.92e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>         <td> 2.864e-05</td> <td> 7.73e-05</td> <td>    0.370</td> <td> 0.711</td> <td>   -0.000</td> <td>    0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                          <td> 1.284e-05</td> <td> 7.46e-06</td> <td>    1.721</td> <td> 0.086</td> <td>-1.83e-06</td> <td> 2.75e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0008</td> <td>    0.000</td> <td>   -2.085</td> <td> 0.038</td> <td>   -0.002</td> <td>-4.68e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>                   <td> -2.53e-07</td> <td>  1.1e-07</td> <td>   -2.292</td> <td> 0.023</td> <td> -4.7e-07</td> <td>-3.59e-08</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>-1.425e-06</td> <td> 1.14e-06</td> <td>   -1.249</td> <td> 0.212</td> <td>-3.67e-06</td> <td> 8.19e-07</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 1.2e+16. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                                                   &        HP        & \\textbf{  R-squared:         } &     0.467   \\\\\n",
       "\\textbf{Model:}                                                           &       OLS        & \\textbf{  Adj. R-squared:    } &     0.369   \\\\\n",
       "\\textbf{Method:}                                                          &  Least Squares   & \\textbf{  F-statistic:       } &     4.764   \\\\\n",
       "\\textbf{Date:}                                                            & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.23e-21   \\\\\n",
       "\\textbf{Time:}                                                            &     17:54:47     & \\textbf{  Log-Likelihood:    } &   -1738.6   \\\\\n",
       "\\textbf{No. Observations:}                                                &         400      & \\textbf{  AIC:               } &     3603.   \\\\\n",
       "\\textbf{Df Residuals:}                                                    &         337      & \\textbf{  BIC:               } &     3855.   \\\\\n",
       "\\textbf{Df Model:}                                                        &          62      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                                                 &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                                          & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                                                        &     521.5715  &      130.273     &     4.004  &         0.000        &      265.322    &      777.821     \\\\\n",
       "\\textbf{Legendary[T.True]}                                                &      -6.1179  &        2.846     &    -2.150  &         0.032        &      -11.716    &       -0.520     \\\\\n",
       "\\textbf{Attack}                                                           &      -8.1938  &        2.329     &    -3.518  &         0.000        &      -12.775    &       -3.612     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]}                                         &   -1224.9610  &      545.105     &    -2.247  &         0.025        &    -2297.199    &     -152.723     \\\\\n",
       "\\textbf{Defense}                                                          &      -6.1989  &        2.174     &    -2.851  &         0.005        &      -10.475    &       -1.923     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]}                                        &    -102.4030  &       96.565     &    -1.060  &         0.290        &     -292.350    &       87.544     \\\\\n",
       "\\textbf{Attack:Defense}                                                   &       0.0985  &        0.033     &     2.982  &         0.003        &        0.034    &        0.164     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]}                                 &      14.6361  &        6.267     &     2.336  &         0.020        &        2.310    &       26.963     \\\\\n",
       "\\textbf{Speed}                                                            &      -7.2261  &        2.178     &    -3.318  &         0.001        &      -11.511    &       -2.942     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]}                                          &     704.8798  &      337.855     &     2.086  &         0.038        &       40.309    &     1369.450     \\\\\n",
       "\\textbf{Attack:Speed}                                                     &       0.1264  &        0.038     &     3.351  &         0.001        &        0.052    &        0.201     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]}                                   &       5.8648  &        2.692     &     2.179  &         0.030        &        0.570    &       11.160     \\\\\n",
       "\\textbf{Defense:Speed}                                                    &       0.1026  &        0.039     &     2.634  &         0.009        &        0.026    &        0.179     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]}                                  &      -6.9266  &        3.465     &    -1.999  &         0.046        &      -13.742    &       -0.111     \\\\\n",
       "\\textbf{Attack:Defense:Speed}                                             &      -0.0016  &        0.001     &    -2.837  &         0.005        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]}                           &      -0.0743  &        0.030     &    -2.477  &         0.014        &       -0.133    &       -0.015     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                                                     &      -5.3982  &        1.938     &    -2.785  &         0.006        &       -9.211    &       -1.586     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\")}                                   &    -282.2496  &      126.835     &    -2.225  &         0.027        &     -531.738    &      -32.761     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                                              &       0.1094  &        0.034     &     3.233  &         0.001        &        0.043    &        0.176     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\")}                            &      12.6503  &        5.851     &     2.162  &         0.031        &        1.141    &       24.160     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\")}                                             &       0.0628  &        0.028     &     2.247  &         0.025        &        0.008    &        0.118     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\")}                           &       3.3949  &        1.783     &     1.904  &         0.058        &       -0.112    &        6.902     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\")}                                      &      -0.0012  &        0.000     &    -2.730  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")}                    &      -0.1456  &        0.065     &    -2.253  &         0.025        &       -0.273    &       -0.018     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                                               &       0.0624  &        0.031     &     2.027  &         0.043        &        0.002    &        0.123     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\")}                             &      -3.2219  &        1.983     &    -1.625  &         0.105        &       -7.122    &        0.678     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}                                        &      -0.0014  &        0.001     &    -2.732  &         0.007        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                      &      -0.0695  &        0.033     &    -2.100  &         0.036        &       -0.135    &       -0.004     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\")}                                       &      -0.0008  &        0.000     &    -1.743  &         0.082        &       -0.002    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}                     &       0.0334  &        0.021     &     1.569  &         0.117        &       -0.008    &        0.075     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\")}                                &    1.629e-05  &     6.92e-06     &     2.355  &         0.019        &     2.68e-06    &     2.99e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")}              &       0.0008  &        0.000     &     2.433  &         0.015        &        0.000    &        0.001     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                                                     &      -8.3636  &        2.346     &    -3.565  &         0.000        &      -12.978    &       -3.749     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Atk\")}                                   &     850.5436  &      385.064     &     2.209  &         0.028        &       93.112    &     1607.975     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                                              &       0.1388  &        0.040     &     3.500  &         0.001        &        0.061    &        0.217     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Atk\")}                            &       2.1809  &        1.136     &     1.920  &         0.056        &       -0.054    &        4.416     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Atk\")}                                             &       0.0831  &        0.038     &     2.162  &         0.031        &        0.007    &        0.159     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                           &      -7.3121  &        3.376     &    -2.166  &         0.031        &      -13.953    &       -0.671     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Atk\")}                                      &      -0.0014  &        0.001     &    -2.480  &         0.014        &       -0.003    &       -0.000     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")}                    &      -0.0434  &        0.022     &    -2.010  &         0.045        &       -0.086    &       -0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                                               &       0.1011  &        0.035     &     2.872  &         0.004        &        0.032    &        0.170     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                             &     -12.6343  &        5.613     &    -2.251  &         0.025        &      -23.674    &       -1.594     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}                                        &      -0.0018  &        0.001     &    -3.102  &         0.002        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                      &       0.0151  &        0.009     &     1.609  &         0.109        &       -0.003    &        0.034     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Atk\")}                                       &      -0.0012  &        0.001     &    -1.860  &         0.064        &       -0.002    &     6.62e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}                     &       0.1210  &        0.054     &     2.260  &         0.024        &        0.016    &        0.226     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Atk\")}                                &    2.125e-05  &      9.1e-06     &     2.334  &         0.020        &     3.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")}              &    6.438e-06  &     7.69e-05     &     0.084  &         0.933        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                        &       0.1265  &        0.033     &     3.821  &         0.000        &        0.061    &        0.192     \\\\\n",
       "\\textbf{Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                      &      -5.0544  &        2.506     &    -2.017  &         0.044        &       -9.983    &       -0.126     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                 &      -0.0021  &        0.001     &    -3.606  &         0.000        &       -0.003    &       -0.001     \\\\\n",
       "\\textbf{Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}               &      -0.0346  &        0.017     &    -1.992  &         0.047        &       -0.069    &       -0.000     \\\\\n",
       "\\textbf{Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                &      -0.0012  &        0.000     &    -2.406  &         0.017        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0446  &        0.025     &     1.794  &         0.074        &       -0.004    &        0.093     \\\\\n",
       "\\textbf{Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                         &    1.973e-05  &     7.28e-06     &     2.710  &         0.007        &     5.41e-06    &      3.4e-05     \\\\\n",
       "\\textbf{Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &       0.0005  &        0.000     &     1.957  &         0.051        &    -2.56e-06    &        0.001     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                                  &      -0.0013  &        0.000     &    -2.740  &         0.006        &       -0.002    &       -0.000     \\\\\n",
       "\\textbf{Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                &       0.0841  &        0.040     &     2.125  &         0.034        &        0.006    &        0.162     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                           &    2.379e-05  &     7.85e-06     &     3.030  &         0.003        &     8.34e-06    &     3.92e-05     \\\\\n",
       "\\textbf{Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}         &    2.864e-05  &     7.73e-05     &     0.370  &         0.711        &       -0.000    &        0.000     \\\\\n",
       "\\textbf{Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                          &    1.284e-05  &     7.46e-06     &     1.721  &         0.086        &    -1.83e-06    &     2.75e-05     \\\\\n",
       "\\textbf{Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0008  &        0.000     &    -2.085  &         0.038        &       -0.002    &    -4.68e-05     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}                   &    -2.53e-07  &      1.1e-07     &    -2.292  &         0.023        &     -4.7e-07    &    -3.59e-08     \\\\\n",
       "\\textbf{Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &   -1.425e-06  &     1.14e-06     &    -1.249  &         0.212        &    -3.67e-06    &     8.19e-07     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 1.2e+16. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.467\n",
       "Model:                            OLS   Adj. R-squared:                  0.369\n",
       "Method:                 Least Squares   F-statistic:                     4.764\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           4.23e-21\n",
       "Time:                        17:54:47   Log-Likelihood:                -1738.6\n",
       "No. Observations:                 400   AIC:                             3603.\n",
       "Df Residuals:                     337   BIC:                             3855.\n",
       "Df Model:                          62                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "====================================================================================================================================\n",
       "                                                                       coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                                          521.5715    130.273      4.004      0.000     265.322     777.821\n",
       "Legendary[T.True]                                                   -6.1179      2.846     -2.150      0.032     -11.716      -0.520\n",
       "Attack                                                              -8.1938      2.329     -3.518      0.000     -12.775      -3.612\n",
       "Attack:Legendary[T.True]                                         -1224.9610    545.105     -2.247      0.025   -2297.199    -152.723\n",
       "Defense                                                             -6.1989      2.174     -2.851      0.005     -10.475      -1.923\n",
       "Defense:Legendary[T.True]                                         -102.4030     96.565     -1.060      0.290    -292.350      87.544\n",
       "Attack:Defense                                                       0.0985      0.033      2.982      0.003       0.034       0.164\n",
       "Attack:Defense:Legendary[T.True]                                    14.6361      6.267      2.336      0.020       2.310      26.963\n",
       "Speed                                                               -7.2261      2.178     -3.318      0.001     -11.511      -2.942\n",
       "Speed:Legendary[T.True]                                            704.8798    337.855      2.086      0.038      40.309    1369.450\n",
       "Attack:Speed                                                         0.1264      0.038      3.351      0.001       0.052       0.201\n",
       "Attack:Speed:Legendary[T.True]                                       5.8648      2.692      2.179      0.030       0.570      11.160\n",
       "Defense:Speed                                                        0.1026      0.039      2.634      0.009       0.026       0.179\n",
       "Defense:Speed:Legendary[T.True]                                     -6.9266      3.465     -1.999      0.046     -13.742      -0.111\n",
       "Attack:Defense:Speed                                                -0.0016      0.001     -2.837      0.005      -0.003      -0.001\n",
       "Attack:Defense:Speed:Legendary[T.True]                              -0.0743      0.030     -2.477      0.014      -0.133      -0.015\n",
       "Q(\"Sp. Def\")                                                        -5.3982      1.938     -2.785      0.006      -9.211      -1.586\n",
       "Legendary[T.True]:Q(\"Sp. Def\")                                    -282.2496    126.835     -2.225      0.027    -531.738     -32.761\n",
       "Attack:Q(\"Sp. Def\")                                                  0.1094      0.034      3.233      0.001       0.043       0.176\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\")                               12.6503      5.851      2.162      0.031       1.141      24.160\n",
       "Defense:Q(\"Sp. Def\")                                                 0.0628      0.028      2.247      0.025       0.008       0.118\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\")                               3.3949      1.783      1.904      0.058      -0.112       6.902\n",
       "Attack:Defense:Q(\"Sp. Def\")                                         -0.0012      0.000     -2.730      0.007      -0.002      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\")                       -0.1456      0.065     -2.253      0.025      -0.273      -0.018\n",
       "Speed:Q(\"Sp. Def\")                                                   0.0624      0.031      2.027      0.043       0.002       0.123\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\")                                -3.2219      1.983     -1.625      0.105      -7.122       0.678\n",
       "Attack:Speed:Q(\"Sp. Def\")                                           -0.0014      0.001     -2.732      0.007      -0.002      -0.000\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         -0.0695      0.033     -2.100      0.036      -0.135      -0.004\n",
       "Defense:Speed:Q(\"Sp. Def\")                                          -0.0008      0.000     -1.743      0.082      -0.002       0.000\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                         0.0334      0.021      1.569      0.117      -0.008       0.075\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\")                                 1.629e-05   6.92e-06      2.355      0.019    2.68e-06    2.99e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\")                  0.0008      0.000      2.433      0.015       0.000       0.001\n",
       "Q(\"Sp. Atk\")                                                        -8.3636      2.346     -3.565      0.000     -12.978      -3.749\n",
       "Legendary[T.True]:Q(\"Sp. Atk\")                                     850.5436    385.064      2.209      0.028      93.112    1607.975\n",
       "Attack:Q(\"Sp. Atk\")                                                  0.1388      0.040      3.500      0.001       0.061       0.217\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Atk\")                                2.1809      1.136      1.920      0.056      -0.054       4.416\n",
       "Defense:Q(\"Sp. Atk\")                                                 0.0831      0.038      2.162      0.031       0.007       0.159\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Atk\")                              -7.3121      3.376     -2.166      0.031     -13.953      -0.671\n",
       "Attack:Defense:Q(\"Sp. Atk\")                                         -0.0014      0.001     -2.480      0.014      -0.003      -0.000\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Atk\")                       -0.0434      0.022     -2.010      0.045      -0.086      -0.001\n",
       "Speed:Q(\"Sp. Atk\")                                                   0.1011      0.035      2.872      0.004       0.032       0.170\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Atk\")                               -12.6343      5.613     -2.251      0.025     -23.674      -1.594\n",
       "Attack:Speed:Q(\"Sp. Atk\")                                           -0.0018      0.001     -3.102      0.002      -0.003      -0.001\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                          0.0151      0.009      1.609      0.109      -0.003       0.034\n",
       "Defense:Speed:Q(\"Sp. Atk\")                                          -0.0012      0.001     -1.860      0.064      -0.002    6.62e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")                         0.1210      0.054      2.260      0.024       0.016       0.226\n",
       "Attack:Defense:Speed:Q(\"Sp. Atk\")                                 2.125e-05    9.1e-06      2.334      0.020    3.34e-06    3.92e-05\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Atk\")               6.438e-06   7.69e-05      0.084      0.933      -0.000       0.000\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                            0.1265      0.033      3.821      0.000       0.061       0.192\n",
       "Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                         -5.0544      2.506     -2.017      0.044      -9.983      -0.126\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                    -0.0021      0.001     -3.606      0.000      -0.003      -0.001\n",
       "Attack:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  -0.0346      0.017     -1.992      0.047      -0.069      -0.000\n",
       "Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                   -0.0012      0.000     -2.406      0.017      -0.002      -0.000\n",
       "Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0446      0.025      1.794      0.074      -0.004       0.093\n",
       "Attack:Defense:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                          1.973e-05   7.28e-06      2.710      0.007    5.41e-06     3.4e-05\n",
       "Attack:Defense:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           0.0005      0.000      1.957      0.051   -2.56e-06       0.001\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                                     -0.0013      0.000     -2.740      0.006      -0.002      -0.000\n",
       "Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    0.0841      0.040      2.125      0.034       0.006       0.162\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                            2.379e-05   7.85e-06      3.030      0.003    8.34e-06    3.92e-05\n",
       "Attack:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          2.864e-05   7.73e-05      0.370      0.711      -0.000       0.000\n",
       "Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                           1.284e-05   7.46e-06      1.721      0.086   -1.83e-06    2.75e-05\n",
       "Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0008      0.000     -2.085      0.038      -0.002   -4.68e-05\n",
       "Attack:Defense:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")                    -2.53e-07    1.1e-07     -2.292      0.023    -4.7e-07   -3.59e-08\n",
       "Attack:Defense:Speed:Legendary[T.True]:Q(\"Sp. Def\"):Q(\"Sp. Atk\") -1.425e-06   1.14e-06     -1.249      0.212   -3.67e-06    8.19e-07\n",
       "==============================================================================\n",
       "Omnibus:                      214.307   Durbin-Watson:                   1.992\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             2354.664\n",
       "Skew:                           2.026   Prob(JB):                         0.00\n",
       "Kurtosis:                      14.174   Cond. No.                     1.20e+16\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 1.2e+16. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form = 'HP ~ Attack * Defense * Speed * Legendary'\n",
    "model4_linear_form += ' * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "# DO NOT try adding '* C(Generation) * C(Q(\"Type 1\")) * C(Q(\"Type 2\"))'\n",
    "# That's 6*18*19 = 6*18*19 possible interaction combinations...\n",
    "# ...a huge number that will blow up your computer\n",
    "\n",
    "model4_spec = smf.ols(formula=model4_linear_form, data=pokeaman_train)\n",
    "model4_fit = model4_spec.fit()\n",
    "model4_fit.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daeb294d",
   "metadata": {},
   "source": [
    "### Cell 4: Specifying a Complex Model (Model 4)\n",
    "1. **Complex Model with Interactions**: Model 4 includes more predictors and interactions among them, such as `Attack * Defense * Speed * Legendary` and other variables. This increases the model's complexity and its potential to fit the training data well.\n",
    "2. **Model Fitting**: As with Model 3, the model is fitted to the training data, and the summary output provides the in-sample R-squared and details about the coefficients.\n",
    "\n",
    "A higher in-sample R-squared here could signal an improved fit but also an increased risk of overfitting due to the added complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9639eac2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.46709442115833855\n",
      "'Out of sample' R-squared: 0.002485342598992873\n"
     ]
    }
   ],
   "source": [
    "yhat_model4 = model4_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model4_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model4)[0,1]**2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b9e9be7",
   "metadata": {},
   "source": [
    "### Cell 5: Calculating In-Sample and Out-of-Sample R-squared for Model 4\n",
    "\n",
    "This cell performs similar steps as in Cell 3 but for Model 4:\n",
    "1. **In-Sample R-squared**: The model4_fit.rsquared provides the in-sample R-squared for Model 4.\n",
    "2. **Out-of-Sample R-squared**: The squared correlation of `y` (test set outcomes) with `yhat_model4` (predictions on the test set) gives the out-of-sample R-squared for Model 4.\n",
    "\n",
    "By comparing these R-squared values, you can determine if the added complexity of Model 4 leads to better generalization. If the out-of-sample R-squared is close to the in-sample value, it suggests generalizability; a large discrepancy could imply overfitting.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f1559a",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4756dde",
   "metadata": {},
   "source": [
    "Here's a summary of our exchanges for your homework submission:\n",
    "\n",
    "---\n",
    "\n",
    "**Objective**: To understand the concepts of training and testing sets, in-sample and out-of-sample testing, and to analyze Model 3 with and without interactions in the context of linear regression.\n",
    "\n",
    "### Key Points Discussed\n",
    "\n",
    "1. **Training and Testing Sets**:\n",
    "   - Defined the **training set** as the data used to fit the model and the **testing set** as data reserved for evaluating model performance on unseen data.\n",
    "   - Clarified that these sets are general concepts in modeling, not specific to this dataset.\n",
    "   \n",
    "2. **In-Sample and Out-of-Sample Testing**:\n",
    "   - Explained that **in-sample testing** uses the training set to evaluate model performance, typically resulting in high accuracy due to the model being optimized for this data.\n",
    "   - **Out-of-sample testing** uses the testing set, providing a more realistic measure of model generalizability.\n",
    "   - Related these concepts to the training and testing sets: in-sample testing aligns with the training set, and out-of-sample testing aligns with the testing set.\n",
    "   - Discussed how discrepancies between in-sample and out-of-sample performance can indicate overfitting.\n",
    "\n",
    "3. **Analysis of Model 3**:\n",
    "   - Identified Model 3 as a **simple linear regression** model with `HP` as the outcome variable, modeled using `Attack` and `Defense` as predictors without interactions.\n",
    "   - Clarified that Model 3 assumes `Attack` and `Defense` independently influence `HP`, meaning each predictor's effect on `HP` does not depend on the other predictor's value.\n",
    "\n",
    "4. **Adding an Interaction Term to Model 3**:\n",
    "   - Provided guidance on modifying the formula to include an interaction term for `Attack` and `Defense`.\n",
    "   - Suggested changing the formula to `HP ~ Attack * Defense` to add both the independent effects and an interaction term (`Attack:Defense`).\n",
    "   - Explained that this modification allows the model to account for cases where the influence of `Attack` on `HP` might vary with `Defense`.\n",
    "\n",
    "---\n",
    "\n",
    "This summary provides a concise record of our discussion for your assignment submission, covering both theoretical explanations and practical coding adjustments. Let me know if you need any further details!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5e1d340",
   "metadata": {},
   "source": [
    "### Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a4a9ea",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/6736196a-cad8-8010-9a44-44a87903b88e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "922446ba",
   "metadata": {},
   "source": [
    "# Question 6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea2b28c7",
   "metadata": {},
   "source": [
    "Steps of how `model4_linear_form` creates new predictor variables in the design matrix\n",
    "why multicollinearity affects out-of-sample generalization\n",
    "\n",
    "#### 1. Creating New Predictor Variables in the Design Matrix\n",
    "- **Model Formula (model4_linear_form)**: The model specification includes `HP ~ Attack * Defense * Speed * Legendary * Q(\"Sp. Def\") * Q(\"Sp. Atk\")`. Here, the `*` operator indicates interactions between all these variables, creating a large number of new predictor variables.\n",
    "- **Design Matrix**: `model4_spec.exog` represents the design matrix, which contains columns for each predictor variable (main effects and interaction terms). Each new column represents a unique interaction or main effect used by the model to predict `HP`.\n",
    "- **Shape of Design Matrix**: `model4_spec.exog.shape` gives the number of rows (observations) and columns (predictors), showing that this model form produces a high-dimensional matrix with numerous predictors due to the multiple interactions.\n",
    "\n",
    "#### 2. Multicollinearity and its Impact on Out-of-Sample Generalization\n",
    "- **Multicollinearity**: In a design matrix with many interactions, some predictors become highly correlated with each other (e.g., `Attack * Speed` and `Defense * Speed`). `np.corrcoef(model4_spec.exog)` would show these correlations. This redundancy makes it difficult for the model to distinguish individual predictor effects.\n",
    "- **Condition Number**: The condition number of the model indicates multicollinearity issues. A very high condition number in `model4_fit.summary()` (12 trillion) indicates severe multicollinearity.\n",
    "- **Effect on Generalization**: High multicollinearity inflates coefficient estimates, making the model very sensitive to minor changes in the data. This results in poor performance when applied to new, out-of-sample data, as the model’s overfit to nuances in the training set leads to inaccurate predictions on the testing set.\n",
    "\n",
    "#### 3. Centering and Scaling\n",
    "- **Centering and Scaling**: Transforming predictors to have a mean of zero and unit variance (using `center` and `scale`) can sometimes reduce multicollinearity, as it normalizes the data. Although centering and scaling reduced the condition number significantly in Model 3, it was less effective in Model 4 due to the complexity of interactions.\n",
    "- **Condition Number After Scaling**: Even after centering and scaling, Model 4’s condition number remains extremely high, indicating that the multicollinearity issue persists and continues to affect out-of-sample generalizability.\n",
    "\n",
    "#### Concise Summary\n",
    "Model 4’s formula introduces many new predictors and interactions in the design matrix, which results in high multicollinearity. This multicollinearity, reflected by a high condition number, inflates coefficient estimates, causing the model to perform well in-sample but poorly out-of-sample due to overfitting. Centering and scaling help reduce the condition number in simpler models but are ineffective in addressing multicollinearity in highly complex models like Model 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b550369",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:54:48</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>   42.5882</td> <td>    3.580</td> <td>   11.897</td> <td> 0.000</td> <td>   35.551</td> <td>   49.626</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>    <td>    0.2472</td> <td>    0.041</td> <td>    6.051</td> <td> 0.000</td> <td>    0.167</td> <td>    0.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>   <td>    0.1001</td> <td>    0.045</td> <td>    2.201</td> <td> 0.028</td> <td>    0.011</td> <td>    0.190</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    343.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}    &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}            &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}           &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}             & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}             &     17:54:48     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:} &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}     &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}         &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}  &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                   & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept} &      42.5882  &        3.580     &    11.897  &         0.000        &       35.551    &       49.626     \\\\\n",
       "\\textbf{Attack}    &       0.2472  &        0.041     &     6.051  &         0.000        &        0.167    &        0.327     \\\\\n",
       "\\textbf{Defense}   &       0.1001  &        0.045     &     2.201  &         0.028        &        0.011    &        0.190     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     343.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        17:54:48   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "Intercept     42.5882      3.580     11.897      0.000      35.551      49.626\n",
       "Attack         0.2472      0.041      6.051      0.000       0.167       0.327\n",
       "Defense        0.1001      0.045      2.201      0.028       0.011       0.190\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         343.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 343.0 WITHOUT to centering and scaling\n",
    "model3_fit.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13f9fd88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.148</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.143</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   34.40</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>1.66e-14</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:54:48</td>     <th>  Log-Likelihood:    </th> <td> -1832.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3671.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   397</td>      <th>  BIC:               </th> <td>   3683.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "             <td></td>               <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>              <td>   69.3025</td> <td>    1.186</td> <td>   58.439</td> <td> 0.000</td> <td>   66.971</td> <td>   71.634</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Attack))</th>  <td>    8.1099</td> <td>    1.340</td> <td>    6.051</td> <td> 0.000</td> <td>    5.475</td> <td>   10.745</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>scale(center(Defense))</th> <td>    2.9496</td> <td>    1.340</td> <td>    2.201</td> <td> 0.028</td> <td>    0.315</td> <td>    5.585</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>284.299</td> <th>  Durbin-Watson:     </th> <td>   2.006</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5870.841</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.720</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>20.963</td>  <th>  Cond. No.          </th> <td>    1.66</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}         &        HP        & \\textbf{  R-squared:         } &     0.148   \\\\\n",
       "\\textbf{Model:}                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.143   \\\\\n",
       "\\textbf{Method:}                &  Least Squares   & \\textbf{  F-statistic:       } &     34.40   \\\\\n",
       "\\textbf{Date:}                  & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  1.66e-14   \\\\\n",
       "\\textbf{Time:}                  &     17:54:48     & \\textbf{  Log-Likelihood:    } &   -1832.6   \\\\\n",
       "\\textbf{No. Observations:}      &         400      & \\textbf{  AIC:               } &     3671.   \\\\\n",
       "\\textbf{Df Residuals:}          &         397      & \\textbf{  BIC:               } &     3683.   \\\\\n",
       "\\textbf{Df Model:}              &           2      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}              &      69.3025  &        1.186     &    58.439  &         0.000        &       66.971    &       71.634     \\\\\n",
       "\\textbf{scale(center(Attack))}  &       8.1099  &        1.340     &     6.051  &         0.000        &        5.475    &       10.745     \\\\\n",
       "\\textbf{scale(center(Defense))} &       2.9496  &        1.340     &     2.201  &         0.028        &        0.315    &        5.585     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 284.299 & \\textbf{  Durbin-Watson:     } &    2.006  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5870.841  \\\\\n",
       "\\textbf{Skew:}          &   2.720 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  20.963 & \\textbf{  Cond. No.          } &     1.66  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.148\n",
       "Model:                            OLS   Adj. R-squared:                  0.143\n",
       "Method:                 Least Squares   F-statistic:                     34.40\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           1.66e-14\n",
       "Time:                        17:54:48   Log-Likelihood:                -1832.6\n",
       "No. Observations:                 400   AIC:                             3671.\n",
       "Df Residuals:                     397   BIC:                             3683.\n",
       "Df Model:                           2                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================\n",
       "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------\n",
       "Intercept                 69.3025      1.186     58.439      0.000      66.971      71.634\n",
       "scale(center(Attack))      8.1099      1.340      6.051      0.000       5.475      10.745\n",
       "scale(center(Defense))     2.9496      1.340      2.201      0.028       0.315       5.585\n",
       "==============================================================================\n",
       "Omnibus:                      284.299   Durbin-Watson:                   2.006\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5870.841\n",
       "Skew:                           2.720   Prob(JB):                         0.00\n",
       "Kurtosis:                      20.963   Cond. No.                         1.66\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from patsy import center, scale\n",
    "\n",
    "model3_linear_form_center_scale = \\\n",
    "  'HP ~ scale(center(Attack)) + scale(center(Defense))' \n",
    "model_spec3_center_scale = smf.ols(formula=model3_linear_form_center_scale,\n",
    "                                   data=pokeaman_train)\n",
    "model3_center_scale_fit = model_spec3_center_scale.fit()\n",
    "model3_center_scale_fit.summary()\n",
    "# \"Cond. No.\" is NOW 1.66 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c18be20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.663</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.54e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.663  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.54e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model4_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Defense))'\n",
    "model4_linear_form_CS += ' * scale(center(Speed)) * Legendary' \n",
    "model4_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# Legendary is an indicator, so we don't center and scale that\n",
    "\n",
    "model4_CS_spec = smf.ols(formula=model4_linear_form_CS, data=pokeaman_train)\n",
    "model4_CS_fit = model4_CS_spec.fit()\n",
    "model4_CS_fit.summary().tables[-1]  # Cond. No. is 2,250,000,000,000,000\n",
    "\n",
    "# The condition number is still bad even after centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38cc2dcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>214.307</td> <th>  Durbin-Watson:     </th> <td>   1.992</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>2354.664</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.026</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>14.174</td>  <th>  Cond. No.          </th> <td>1.20e+16</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 214.307 & \\textbf{  Durbin-Watson:     } &    1.992  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 2354.664  \\\\\n",
       "\\textbf{Skew:}          &   2.026 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  14.174 & \\textbf{  Cond. No.          } & 1.20e+16  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just as the condition number was very bad to start with\n",
    "model4_fit.summary().tables[-1]  # Cond. No. is 12,000,000,000,000,000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2952c7f",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cf66aa0",
   "metadata": {},
   "source": [
    "Here’s a summary of our exchanges for your homework submission:\n",
    "\n",
    "---\n",
    "\n",
    "**Objective**: To understand the design matrix, multicollinearity, and how these concepts relate to model generalization and out-of-sample performance.\n",
    "\n",
    "### Key Points Discussed\n",
    "\n",
    "1. **Design Matrix**:\n",
    "   - Defined the **design matrix** as the structured matrix representation of predictor variables used in regression models.\n",
    "   - Explained that each row represents an observation and each column represents a predictor variable, including any interaction terms.\n",
    "   - Noted that complex models like Model 4 create a large number of columns in the design matrix by adding interactions, increasing model complexity and potentially introducing multicollinearity.\n",
    "\n",
    "2. **Multicollinearity**:\n",
    "   - Defined **multicollinearity** as the high correlation between predictor variables, resulting in redundancy within the design matrix.\n",
    "   - Highlighted that multicollinearity causes instability in coefficient estimates, increased standard errors, and difficulties in determining the significance of individual predictors.\n",
    "   - Discussed the condition number as a diagnostic metric: a high condition number indicates multicollinearity, as seen in Model 4's design matrix.\n",
    "\n",
    "3. **Impact on Model Generalization**:\n",
    "   - Explained how multicollinearity affects **generalizability** by making models sensitive to small data changes, reducing their reliability in predicting new, out-of-sample data.\n",
    "   - Clarified that while multicollinearity may not harm in-sample fit, it can lead to overfitting, where the model performs well on training data but poorly on testing data.\n",
    "\n",
    "4. **Centering and Scaling**:\n",
    "   - Introduced **centering and scaling** as techniques to address multicollinearity by normalizing predictor variables, which can reduce redundancy.\n",
    "   - Although these techniques improved Model 3’s condition number, Model 4’s high-dimensional design matrix with interactions remained highly collinear even after centering and scaling.\n",
    "\n",
    "### Summary\n",
    "In summary, our discussion covered how the design matrix forms the basis of the regression model by structuring predictors and interactions, and how multicollinearity within this matrix can negatively impact model generalizability. We explored how multicollinearity inflates standard errors, complicates coefficient interpretation, and contributes to overfitting. We also reviewed centering and scaling as partial remedies for multicollinearity, with limited success in complex models with many interactions, like Model 4.\n",
    "\n",
    "---\n",
    "\n",
    "This summary should serve as a clear record of our discussion for your assignment. Let me know if any further details are needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b70b7670",
   "metadata": {},
   "source": [
    "#### Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54011063",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/6736196a-cad8-8010-9a44-44a87903b88e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb5afff4",
   "metadata": {},
   "source": [
    "# Question 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ee2a8e5",
   "metadata": {},
   "source": [
    "\n",
    "#### Model 5\n",
    "- **Rationale**: Model 5 expands from Model 3 and Model 4 by including more main effect predictors without interactions. It adds `Speed`, `Legendary` status, `Sp. Def`, `Sp. Atk`, and categorical predictors like `Generation` and `Type`.\n",
    "- **Principle**: This model explores a comprehensive set of individual effects on `HP` while avoiding the complexity of interaction terms to see if these predictors collectively improve the model’s accuracy without overfitting.\n",
    "\n",
    "#### Model 6\n",
    "- **Rationale**: Model 6 is a simplified version of Model 5 that selectively retains only the most significant predictors from Model 5.\n",
    "- **Principle**: This approach uses the statistical significance of predictors identified in Model 5 to create a more focused model, hypothesizing that fewer, significant predictors might yield similar or improved out-of-sample performance by reducing multicollinearity and overfitting.\n",
    "\n",
    "#### Model 7\n",
    "- **Rationale**: Model 7 builds on Model 6 by reintroducing interactions between `Attack`, `Speed`, `Sp. Def`, and `Sp. Atk`, which might capture combined effects that weren’t fully expressed in simpler models.\n",
    "- **Principle**: This model tests the hypothesis that some predictor combinations (interactions) can add predictive power without the excessive complexity seen in Model 4. Additionally, Model 7 introduces centering and scaling to address multicollinearity, particularly important with interaction terms.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "79dc3a76",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.313</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   4.948</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>9.48e-19</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:54:48</td>     <th>  Log-Likelihood:    </th> <td> -1765.0</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3624.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   353</td>      <th>  BIC:               </th> <td>   3812.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    46</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "               <td></td>                 <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                  <td>   10.1046</td> <td>   14.957</td> <td>    0.676</td> <td> 0.500</td> <td>  -19.312</td> <td>   39.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Legendary[T.True]</th>          <td>   -3.2717</td> <td>    4.943</td> <td>   -0.662</td> <td> 0.508</td> <td>  -12.992</td> <td>    6.449</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.2]</th>         <td>    9.2938</td> <td>    4.015</td> <td>    2.315</td> <td> 0.021</td> <td>    1.398</td> <td>   17.189</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.3]</th>         <td>    2.3150</td> <td>    3.915</td> <td>    0.591</td> <td> 0.555</td> <td>   -5.385</td> <td>   10.015</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.4]</th>         <td>    4.8353</td> <td>    4.149</td> <td>    1.165</td> <td> 0.245</td> <td>   -3.325</td> <td>   12.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.5]</th>         <td>   11.4838</td> <td>    3.960</td> <td>    2.900</td> <td> 0.004</td> <td>    3.696</td> <td>   19.272</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Generation)[T.6]</th>         <td>    4.9206</td> <td>    4.746</td> <td>    1.037</td> <td> 0.300</td> <td>   -4.413</td> <td>   14.254</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dark]</th>     <td>   -1.4155</td> <td>    6.936</td> <td>   -0.204</td> <td> 0.838</td> <td>  -15.057</td> <td>   12.226</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Dragon]</th>   <td>    0.8509</td> <td>    6.900</td> <td>    0.123</td> <td> 0.902</td> <td>  -12.720</td> <td>   14.422</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Electric]</th> <td>   -6.3641</td> <td>    6.537</td> <td>   -0.974</td> <td> 0.331</td> <td>  -19.220</td> <td>    6.491</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fairy]</th>    <td>   -1.9486</td> <td>   10.124</td> <td>   -0.192</td> <td> 0.847</td> <td>  -21.859</td> <td>   17.962</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fighting]</th> <td>    7.0308</td> <td>    7.432</td> <td>    0.946</td> <td> 0.345</td> <td>   -7.586</td> <td>   21.648</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Fire]</th>     <td>    3.0779</td> <td>    6.677</td> <td>    0.461</td> <td> 0.645</td> <td>  -10.055</td> <td>   16.210</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Flying]</th>   <td>   -2.1231</td> <td>   22.322</td> <td>   -0.095</td> <td> 0.924</td> <td>  -46.025</td> <td>   41.779</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ghost]</th>    <td>    5.7343</td> <td>    8.488</td> <td>    0.676</td> <td> 0.500</td> <td>  -10.960</td> <td>   22.429</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Grass]</th>    <td>    3.3275</td> <td>    5.496</td> <td>    0.605</td> <td> 0.545</td> <td>   -7.481</td> <td>   14.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ground]</th>   <td>    9.5118</td> <td>    7.076</td> <td>    1.344</td> <td> 0.180</td> <td>   -4.404</td> <td>   23.428</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Ice]</th>      <td>   -0.9313</td> <td>    7.717</td> <td>   -0.121</td> <td> 0.904</td> <td>  -16.108</td> <td>   14.246</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Normal]</th>   <td>   18.4816</td> <td>    5.312</td> <td>    3.479</td> <td> 0.001</td> <td>    8.034</td> <td>   28.929</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Poison]</th>   <td>    8.3411</td> <td>    7.735</td> <td>    1.078</td> <td> 0.282</td> <td>   -6.871</td> <td>   23.554</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Psychic]</th>  <td>    1.8061</td> <td>    6.164</td> <td>    0.293</td> <td> 0.770</td> <td>  -10.317</td> <td>   13.930</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Rock]</th>     <td>   -3.8558</td> <td>    6.503</td> <td>   -0.593</td> <td> 0.554</td> <td>  -16.645</td> <td>    8.933</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Steel]</th>    <td>   -4.0053</td> <td>    8.044</td> <td>   -0.498</td> <td> 0.619</td> <td>  -19.826</td> <td>   11.816</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 1\"))[T.Water]</th>    <td>    9.7988</td> <td>    5.166</td> <td>    1.897</td> <td> 0.059</td> <td>   -0.361</td> <td>   19.959</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dark]</th>     <td>    5.8719</td> <td>   15.185</td> <td>    0.387</td> <td> 0.699</td> <td>  -23.993</td> <td>   35.737</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Dragon]</th>   <td>   13.2777</td> <td>   14.895</td> <td>    0.891</td> <td> 0.373</td> <td>  -16.016</td> <td>   42.571</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Electric]</th> <td>   14.3228</td> <td>   17.314</td> <td>    0.827</td> <td> 0.409</td> <td>  -19.728</td> <td>   48.374</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fairy]</th>    <td>    2.8426</td> <td>   14.268</td> <td>    0.199</td> <td> 0.842</td> <td>  -25.218</td> <td>   30.903</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fighting]</th> <td>    1.9741</td> <td>   14.089</td> <td>    0.140</td> <td> 0.889</td> <td>  -25.735</td> <td>   29.683</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Fire]</th>     <td>    0.2001</td> <td>   15.730</td> <td>    0.013</td> <td> 0.990</td> <td>  -30.736</td> <td>   31.136</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Flying]</th>   <td>    6.7292</td> <td>   13.581</td> <td>    0.495</td> <td> 0.621</td> <td>  -19.980</td> <td>   33.438</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ghost]</th>    <td>  -10.9402</td> <td>   15.895</td> <td>   -0.688</td> <td> 0.492</td> <td>  -42.201</td> <td>   20.321</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Grass]</th>    <td>    2.5119</td> <td>   14.540</td> <td>    0.173</td> <td> 0.863</td> <td>  -26.084</td> <td>   31.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ground]</th>   <td>   13.6042</td> <td>   13.655</td> <td>    0.996</td> <td> 0.320</td> <td>  -13.250</td> <td>   40.459</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Ice]</th>      <td>   19.7950</td> <td>   15.068</td> <td>    1.314</td> <td> 0.190</td> <td>   -9.840</td> <td>   49.430</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.None]</th>     <td>    7.6068</td> <td>   13.162</td> <td>    0.578</td> <td> 0.564</td> <td>  -18.279</td> <td>   33.493</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Normal]</th>   <td>   17.3191</td> <td>   17.764</td> <td>    0.975</td> <td> 0.330</td> <td>  -17.618</td> <td>   52.256</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Poison]</th>   <td>    0.7770</td> <td>   14.575</td> <td>    0.053</td> <td> 0.958</td> <td>  -27.887</td> <td>   29.441</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Psychic]</th>  <td>    4.2480</td> <td>   14.174</td> <td>    0.300</td> <td> 0.765</td> <td>  -23.628</td> <td>   32.124</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Rock]</th>     <td>    6.8858</td> <td>   16.221</td> <td>    0.424</td> <td> 0.671</td> <td>  -25.017</td> <td>   38.788</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Steel]</th>    <td>  -11.9623</td> <td>   14.973</td> <td>   -0.799</td> <td> 0.425</td> <td>  -41.409</td> <td>   17.485</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Q(\"Type 2\"))[T.Water]</th>    <td>    5.8097</td> <td>   14.763</td> <td>    0.394</td> <td> 0.694</td> <td>  -23.225</td> <td>   34.845</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                     <td>    0.2508</td> <td>    0.051</td> <td>    4.940</td> <td> 0.000</td> <td>    0.151</td> <td>    0.351</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Defense</th>                    <td>   -0.0096</td> <td>    0.060</td> <td>   -0.160</td> <td> 0.873</td> <td>   -0.127</td> <td>    0.108</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                      <td>   -0.1538</td> <td>    0.051</td> <td>   -2.998</td> <td> 0.003</td> <td>   -0.255</td> <td>   -0.053</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>               <td>    0.3484</td> <td>    0.059</td> <td>    5.936</td> <td> 0.000</td> <td>    0.233</td> <td>    0.464</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>               <td>    0.1298</td> <td>    0.051</td> <td>    2.525</td> <td> 0.012</td> <td>    0.029</td> <td>    0.231</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>286.476</td> <th>  Durbin-Watson:     </th> <td>   1.917</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>5187.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.807</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>19.725</td>  <th>  Cond. No.          </th> <td>9.21e+03</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 9.21e+03. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}             &        HP        & \\textbf{  R-squared:         } &     0.392   \\\\\n",
       "\\textbf{Model:}                     &       OLS        & \\textbf{  Adj. R-squared:    } &     0.313   \\\\\n",
       "\\textbf{Method:}                    &  Least Squares   & \\textbf{  F-statistic:       } &     4.948   \\\\\n",
       "\\textbf{Date:}                      & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  9.48e-19   \\\\\n",
       "\\textbf{Time:}                      &     17:54:48     & \\textbf{  Log-Likelihood:    } &   -1765.0   \\\\\n",
       "\\textbf{No. Observations:}          &         400      & \\textbf{  AIC:               } &     3624.   \\\\\n",
       "\\textbf{Df Residuals:}              &         353      & \\textbf{  BIC:               } &     3812.   \\\\\n",
       "\\textbf{Df Model:}                  &          46      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}           &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                    & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                  &      10.1046  &       14.957     &     0.676  &         0.500        &      -19.312    &       39.521     \\\\\n",
       "\\textbf{Legendary[T.True]}          &      -3.2717  &        4.943     &    -0.662  &         0.508        &      -12.992    &        6.449     \\\\\n",
       "\\textbf{C(Generation)[T.2]}         &       9.2938  &        4.015     &     2.315  &         0.021        &        1.398    &       17.189     \\\\\n",
       "\\textbf{C(Generation)[T.3]}         &       2.3150  &        3.915     &     0.591  &         0.555        &       -5.385    &       10.015     \\\\\n",
       "\\textbf{C(Generation)[T.4]}         &       4.8353  &        4.149     &     1.165  &         0.245        &       -3.325    &       12.995     \\\\\n",
       "\\textbf{C(Generation)[T.5]}         &      11.4838  &        3.960     &     2.900  &         0.004        &        3.696    &       19.272     \\\\\n",
       "\\textbf{C(Generation)[T.6]}         &       4.9206  &        4.746     &     1.037  &         0.300        &       -4.413    &       14.254     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dark]}     &      -1.4155  &        6.936     &    -0.204  &         0.838        &      -15.057    &       12.226     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Dragon]}   &       0.8509  &        6.900     &     0.123  &         0.902        &      -12.720    &       14.422     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Electric]} &      -6.3641  &        6.537     &    -0.974  &         0.331        &      -19.220    &        6.491     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fairy]}    &      -1.9486  &       10.124     &    -0.192  &         0.847        &      -21.859    &       17.962     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fighting]} &       7.0308  &        7.432     &     0.946  &         0.345        &       -7.586    &       21.648     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Fire]}     &       3.0779  &        6.677     &     0.461  &         0.645        &      -10.055    &       16.210     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Flying]}   &      -2.1231  &       22.322     &    -0.095  &         0.924        &      -46.025    &       41.779     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ghost]}    &       5.7343  &        8.488     &     0.676  &         0.500        &      -10.960    &       22.429     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Grass]}    &       3.3275  &        5.496     &     0.605  &         0.545        &       -7.481    &       14.136     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ground]}   &       9.5118  &        7.076     &     1.344  &         0.180        &       -4.404    &       23.428     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Ice]}      &      -0.9313  &        7.717     &    -0.121  &         0.904        &      -16.108    &       14.246     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Normal]}   &      18.4816  &        5.312     &     3.479  &         0.001        &        8.034    &       28.929     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Poison]}   &       8.3411  &        7.735     &     1.078  &         0.282        &       -6.871    &       23.554     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Psychic]}  &       1.8061  &        6.164     &     0.293  &         0.770        &      -10.317    &       13.930     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Rock]}     &      -3.8558  &        6.503     &    -0.593  &         0.554        &      -16.645    &        8.933     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Steel]}    &      -4.0053  &        8.044     &    -0.498  &         0.619        &      -19.826    &       11.816     \\\\\n",
       "\\textbf{C(Q(\"Type 1\"))[T.Water]}    &       9.7988  &        5.166     &     1.897  &         0.059        &       -0.361    &       19.959     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dark]}     &       5.8719  &       15.185     &     0.387  &         0.699        &      -23.993    &       35.737     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Dragon]}   &      13.2777  &       14.895     &     0.891  &         0.373        &      -16.016    &       42.571     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Electric]} &      14.3228  &       17.314     &     0.827  &         0.409        &      -19.728    &       48.374     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fairy]}    &       2.8426  &       14.268     &     0.199  &         0.842        &      -25.218    &       30.903     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fighting]} &       1.9741  &       14.089     &     0.140  &         0.889        &      -25.735    &       29.683     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Fire]}     &       0.2001  &       15.730     &     0.013  &         0.990        &      -30.736    &       31.136     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Flying]}   &       6.7292  &       13.581     &     0.495  &         0.621        &      -19.980    &       33.438     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ghost]}    &     -10.9402  &       15.895     &    -0.688  &         0.492        &      -42.201    &       20.321     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Grass]}    &       2.5119  &       14.540     &     0.173  &         0.863        &      -26.084    &       31.108     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ground]}   &      13.6042  &       13.655     &     0.996  &         0.320        &      -13.250    &       40.459     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Ice]}      &      19.7950  &       15.068     &     1.314  &         0.190        &       -9.840    &       49.430     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.None]}     &       7.6068  &       13.162     &     0.578  &         0.564        &      -18.279    &       33.493     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Normal]}   &      17.3191  &       17.764     &     0.975  &         0.330        &      -17.618    &       52.256     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Poison]}   &       0.7770  &       14.575     &     0.053  &         0.958        &      -27.887    &       29.441     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Psychic]}  &       4.2480  &       14.174     &     0.300  &         0.765        &      -23.628    &       32.124     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Rock]}     &       6.8858  &       16.221     &     0.424  &         0.671        &      -25.017    &       38.788     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Steel]}    &     -11.9623  &       14.973     &    -0.799  &         0.425        &      -41.409    &       17.485     \\\\\n",
       "\\textbf{C(Q(\"Type 2\"))[T.Water]}    &       5.8097  &       14.763     &     0.394  &         0.694        &      -23.225    &       34.845     \\\\\n",
       "\\textbf{Attack}                     &       0.2508  &        0.051     &     4.940  &         0.000        &        0.151    &        0.351     \\\\\n",
       "\\textbf{Defense}                    &      -0.0096  &        0.060     &    -0.160  &         0.873        &       -0.127    &        0.108     \\\\\n",
       "\\textbf{Speed}                      &      -0.1538  &        0.051     &    -2.998  &         0.003        &       -0.255    &       -0.053     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}               &       0.3484  &        0.059     &     5.936  &         0.000        &        0.233    &        0.464     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}               &       0.1298  &        0.051     &     2.525  &         0.012        &        0.029    &        0.231     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 286.476 & \\textbf{  Durbin-Watson:     } &    1.917  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 5187.327  \\\\\n",
       "\\textbf{Skew:}          &   2.807 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  19.725 & \\textbf{  Cond. No.          } & 9.21e+03  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 9.21e+03. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.392\n",
       "Model:                            OLS   Adj. R-squared:                  0.313\n",
       "Method:                 Least Squares   F-statistic:                     4.948\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           9.48e-19\n",
       "Time:                        17:54:48   Log-Likelihood:                -1765.0\n",
       "No. Observations:                 400   AIC:                             3624.\n",
       "Df Residuals:                     353   BIC:                             3812.\n",
       "Df Model:                          46                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================================\n",
       "                                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------\n",
       "Intercept                     10.1046     14.957      0.676      0.500     -19.312      39.521\n",
       "Legendary[T.True]             -3.2717      4.943     -0.662      0.508     -12.992       6.449\n",
       "C(Generation)[T.2]             9.2938      4.015      2.315      0.021       1.398      17.189\n",
       "C(Generation)[T.3]             2.3150      3.915      0.591      0.555      -5.385      10.015\n",
       "C(Generation)[T.4]             4.8353      4.149      1.165      0.245      -3.325      12.995\n",
       "C(Generation)[T.5]            11.4838      3.960      2.900      0.004       3.696      19.272\n",
       "C(Generation)[T.6]             4.9206      4.746      1.037      0.300      -4.413      14.254\n",
       "C(Q(\"Type 1\"))[T.Dark]        -1.4155      6.936     -0.204      0.838     -15.057      12.226\n",
       "C(Q(\"Type 1\"))[T.Dragon]       0.8509      6.900      0.123      0.902     -12.720      14.422\n",
       "C(Q(\"Type 1\"))[T.Electric]    -6.3641      6.537     -0.974      0.331     -19.220       6.491\n",
       "C(Q(\"Type 1\"))[T.Fairy]       -1.9486     10.124     -0.192      0.847     -21.859      17.962\n",
       "C(Q(\"Type 1\"))[T.Fighting]     7.0308      7.432      0.946      0.345      -7.586      21.648\n",
       "C(Q(\"Type 1\"))[T.Fire]         3.0779      6.677      0.461      0.645     -10.055      16.210\n",
       "C(Q(\"Type 1\"))[T.Flying]      -2.1231     22.322     -0.095      0.924     -46.025      41.779\n",
       "C(Q(\"Type 1\"))[T.Ghost]        5.7343      8.488      0.676      0.500     -10.960      22.429\n",
       "C(Q(\"Type 1\"))[T.Grass]        3.3275      5.496      0.605      0.545      -7.481      14.136\n",
       "C(Q(\"Type 1\"))[T.Ground]       9.5118      7.076      1.344      0.180      -4.404      23.428\n",
       "C(Q(\"Type 1\"))[T.Ice]         -0.9313      7.717     -0.121      0.904     -16.108      14.246\n",
       "C(Q(\"Type 1\"))[T.Normal]      18.4816      5.312      3.479      0.001       8.034      28.929\n",
       "C(Q(\"Type 1\"))[T.Poison]       8.3411      7.735      1.078      0.282      -6.871      23.554\n",
       "C(Q(\"Type 1\"))[T.Psychic]      1.8061      6.164      0.293      0.770     -10.317      13.930\n",
       "C(Q(\"Type 1\"))[T.Rock]        -3.8558      6.503     -0.593      0.554     -16.645       8.933\n",
       "C(Q(\"Type 1\"))[T.Steel]       -4.0053      8.044     -0.498      0.619     -19.826      11.816\n",
       "C(Q(\"Type 1\"))[T.Water]        9.7988      5.166      1.897      0.059      -0.361      19.959\n",
       "C(Q(\"Type 2\"))[T.Dark]         5.8719     15.185      0.387      0.699     -23.993      35.737\n",
       "C(Q(\"Type 2\"))[T.Dragon]      13.2777     14.895      0.891      0.373     -16.016      42.571\n",
       "C(Q(\"Type 2\"))[T.Electric]    14.3228     17.314      0.827      0.409     -19.728      48.374\n",
       "C(Q(\"Type 2\"))[T.Fairy]        2.8426     14.268      0.199      0.842     -25.218      30.903\n",
       "C(Q(\"Type 2\"))[T.Fighting]     1.9741     14.089      0.140      0.889     -25.735      29.683\n",
       "C(Q(\"Type 2\"))[T.Fire]         0.2001     15.730      0.013      0.990     -30.736      31.136\n",
       "C(Q(\"Type 2\"))[T.Flying]       6.7292     13.581      0.495      0.621     -19.980      33.438\n",
       "C(Q(\"Type 2\"))[T.Ghost]      -10.9402     15.895     -0.688      0.492     -42.201      20.321\n",
       "C(Q(\"Type 2\"))[T.Grass]        2.5119     14.540      0.173      0.863     -26.084      31.108\n",
       "C(Q(\"Type 2\"))[T.Ground]      13.6042     13.655      0.996      0.320     -13.250      40.459\n",
       "C(Q(\"Type 2\"))[T.Ice]         19.7950     15.068      1.314      0.190      -9.840      49.430\n",
       "C(Q(\"Type 2\"))[T.None]         7.6068     13.162      0.578      0.564     -18.279      33.493\n",
       "C(Q(\"Type 2\"))[T.Normal]      17.3191     17.764      0.975      0.330     -17.618      52.256\n",
       "C(Q(\"Type 2\"))[T.Poison]       0.7770     14.575      0.053      0.958     -27.887      29.441\n",
       "C(Q(\"Type 2\"))[T.Psychic]      4.2480     14.174      0.300      0.765     -23.628      32.124\n",
       "C(Q(\"Type 2\"))[T.Rock]         6.8858     16.221      0.424      0.671     -25.017      38.788\n",
       "C(Q(\"Type 2\"))[T.Steel]      -11.9623     14.973     -0.799      0.425     -41.409      17.485\n",
       "C(Q(\"Type 2\"))[T.Water]        5.8097     14.763      0.394      0.694     -23.225      34.845\n",
       "Attack                         0.2508      0.051      4.940      0.000       0.151       0.351\n",
       "Defense                       -0.0096      0.060     -0.160      0.873      -0.127       0.108\n",
       "Speed                         -0.1538      0.051     -2.998      0.003      -0.255      -0.053\n",
       "Q(\"Sp. Def\")                   0.3484      0.059      5.936      0.000       0.233       0.464\n",
       "Q(\"Sp. Atk\")                   0.1298      0.051      2.525      0.012       0.029       0.231\n",
       "==============================================================================\n",
       "Omnibus:                      286.476   Durbin-Watson:                   1.917\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5187.327\n",
       "Skew:                           2.807   Prob(JB):                         0.00\n",
       "Kurtosis:                      19.725   Cond. No.                     9.21e+03\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 9.21e+03. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model5_linear_form = 'HP ~ Attack + Defense + Speed + Legendary'\n",
    "model5_linear_form += ' + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "model5_linear_form += ' + C(Generation) + C(Q(\"Type 1\")) + C(Q(\"Type 2\"))'\n",
    "\n",
    "model5_spec = smf.ols(formula=model5_linear_form, data=pokeaman_train)\n",
    "model5_fit = model5_spec.fit()\n",
    "model5_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dffafd1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3920134083531893\n",
      "'Out of sample' R-squared: 0.30015614488652215\n"
     ]
    }
   ],
   "source": [
    "yhat_model5 = model5_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model5_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model5)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "79f58db8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.333</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.319</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   24.36</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>2.25e-30</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:54:48</td>     <th>  Log-Likelihood:    </th> <td> -1783.6</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3585.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   391</td>      <th>  BIC:               </th> <td>   3621.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     8</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                   <td></td>                     <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                          <td>   22.8587</td> <td>    3.876</td> <td>    5.897</td> <td> 0.000</td> <td>   15.238</td> <td>   30.479</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th> <td>   17.5594</td> <td>    3.339</td> <td>    5.258</td> <td> 0.000</td> <td>   10.994</td> <td>   24.125</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>  <td>    9.0301</td> <td>    3.172</td> <td>    2.847</td> <td> 0.005</td> <td>    2.794</td> <td>   15.266</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>         <td>    6.5293</td> <td>    2.949</td> <td>    2.214</td> <td> 0.027</td> <td>    0.732</td> <td>   12.327</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>         <td>    8.4406</td> <td>    2.711</td> <td>    3.114</td> <td> 0.002</td> <td>    3.112</td> <td>   13.770</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                             <td>    0.2454</td> <td>    0.037</td> <td>    6.639</td> <td> 0.000</td> <td>    0.173</td> <td>    0.318</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                              <td>   -0.1370</td> <td>    0.045</td> <td>   -3.028</td> <td> 0.003</td> <td>   -0.226</td> <td>   -0.048</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                       <td>    0.3002</td> <td>    0.045</td> <td>    6.662</td> <td> 0.000</td> <td>    0.212</td> <td>    0.389</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                       <td>    0.1192</td> <td>    0.042</td> <td>    2.828</td> <td> 0.005</td> <td>    0.036</td> <td>    0.202</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>271.290</td> <th>  Durbin-Watson:     </th> <td>   1.999</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>4238.692</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.651</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>18.040</td>  <th>  Cond. No.          </th> <td>    618.</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                     &        HP        & \\textbf{  R-squared:         } &     0.333   \\\\\n",
       "\\textbf{Model:}                             &       OLS        & \\textbf{  Adj. R-squared:    } &     0.319   \\\\\n",
       "\\textbf{Method:}                            &  Least Squares   & \\textbf{  F-statistic:       } &     24.36   \\\\\n",
       "\\textbf{Date:}                              & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  2.25e-30   \\\\\n",
       "\\textbf{Time:}                              &     17:54:48     & \\textbf{  Log-Likelihood:    } &   -1783.6   \\\\\n",
       "\\textbf{No. Observations:}                  &         400      & \\textbf{  AIC:               } &     3585.   \\\\\n",
       "\\textbf{Df Residuals:}                      &         391      & \\textbf{  BIC:               } &     3621.   \\\\\n",
       "\\textbf{Df Model:}                          &           8      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                   &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                            & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                          &      22.8587  &        3.876     &     5.897  &         0.000        &       15.238    &       30.479     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]} &      17.5594  &        3.339     &     5.258  &         0.000        &       10.994    &       24.125     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}  &       9.0301  &        3.172     &     2.847  &         0.005        &        2.794    &       15.266     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}         &       6.5293  &        2.949     &     2.214  &         0.027        &        0.732    &       12.327     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}         &       8.4406  &        2.711     &     3.114  &         0.002        &        3.112    &       13.770     \\\\\n",
       "\\textbf{Attack}                             &       0.2454  &        0.037     &     6.639  &         0.000        &        0.173    &        0.318     \\\\\n",
       "\\textbf{Speed}                              &      -0.1370  &        0.045     &    -3.028  &         0.003        &       -0.226    &       -0.048     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                       &       0.3002  &        0.045     &     6.662  &         0.000        &        0.212    &        0.389     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                       &       0.1192  &        0.042     &     2.828  &         0.005        &        0.036    &        0.202     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 271.290 & \\textbf{  Durbin-Watson:     } &    1.999  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 4238.692  \\\\\n",
       "\\textbf{Skew:}          &   2.651 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  18.040 & \\textbf{  Cond. No.          } &     618.  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.333\n",
       "Model:                            OLS   Adj. R-squared:                  0.319\n",
       "Method:                 Least Squares   F-statistic:                     24.36\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           2.25e-30\n",
       "Time:                        17:54:48   Log-Likelihood:                -1783.6\n",
       "No. Observations:                 400   AIC:                             3585.\n",
       "Df Residuals:                     391   BIC:                             3621.\n",
       "Df Model:                           8                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "======================================================================================================\n",
       "                                         coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------------------------------\n",
       "Intercept                             22.8587      3.876      5.897      0.000      15.238      30.479\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]    17.5594      3.339      5.258      0.000      10.994      24.125\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]      9.0301      3.172      2.847      0.005       2.794      15.266\n",
       "I(Generation == 2)[T.True]             6.5293      2.949      2.214      0.027       0.732      12.327\n",
       "I(Generation == 5)[T.True]             8.4406      2.711      3.114      0.002       3.112      13.770\n",
       "Attack                                 0.2454      0.037      6.639      0.000       0.173       0.318\n",
       "Speed                                 -0.1370      0.045     -3.028      0.003      -0.226      -0.048\n",
       "Q(\"Sp. Def\")                           0.3002      0.045      6.662      0.000       0.212       0.389\n",
       "Q(\"Sp. Atk\")                           0.1192      0.042      2.828      0.005       0.036       0.202\n",
       "==============================================================================\n",
       "Omnibus:                      271.290   Durbin-Watson:                   1.999\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             4238.692\n",
       "Skew:                           2.651   Prob(JB):                         0.00\n",
       "Kurtosis:                      18.040   Cond. No.                         618.\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Here's something a little more reasonable...\n",
    "model6_linear_form = 'HP ~ Attack + Speed + Q(\"Sp. Def\") + Q(\"Sp. Atk\")'\n",
    "# And here we'll add the significant indicators from the previous model\n",
    "# https://chatgpt.com/share/81ab88df-4f07-49f9-a44a-de0cfd89c67c\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model6_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model6_linear_form += ' + I(Generation==2)'\n",
    "model6_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model6_spec = smf.ols(formula=model6_linear_form, data=pokeaman_train)\n",
    "model6_fit = model6_spec.fit()\n",
    "model6_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "086d9d26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908\n",
      "'Out of sample' R-squared: 0.29572460427079933\n"
     ]
    }
   ],
   "source": [
    "yhat_model6 = model6_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c2797224",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>           <td>HP</td>        <th>  R-squared:         </th> <td>   0.378</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.347</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   12.16</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Thu, 14 Nov 2024</td> <th>  Prob (F-statistic):</th> <td>4.20e-29</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>17:54:48</td>     <th>  Log-Likelihood:    </th> <td> -1769.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>   400</td>      <th>  AIC:               </th> <td>   3579.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>   380</td>      <th>  BIC:               </th> <td>   3659.</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>    19</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                     <td></td>                       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                              <td>   95.1698</td> <td>   34.781</td> <td>    2.736</td> <td> 0.007</td> <td>   26.783</td> <td>  163.556</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Normal\")[T.True]</th>     <td>   18.3653</td> <td>    3.373</td> <td>    5.445</td> <td> 0.000</td> <td>   11.733</td> <td>   24.997</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Q(\"Type 1\") == \"Water\")[T.True]</th>      <td>    9.2913</td> <td>    3.140</td> <td>    2.959</td> <td> 0.003</td> <td>    3.117</td> <td>   15.466</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 2)[T.True]</th>             <td>    7.0711</td> <td>    2.950</td> <td>    2.397</td> <td> 0.017</td> <td>    1.271</td> <td>   12.871</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>I(Generation == 5)[T.True]</th>             <td>    7.8557</td> <td>    2.687</td> <td>    2.923</td> <td> 0.004</td> <td>    2.572</td> <td>   13.140</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack</th>                                 <td>   -0.6975</td> <td>    0.458</td> <td>   -1.523</td> <td> 0.129</td> <td>   -1.598</td> <td>    0.203</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed</th>                                  <td>   -1.8147</td> <td>    0.554</td> <td>   -3.274</td> <td> 0.001</td> <td>   -2.905</td> <td>   -0.725</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed</th>                           <td>    0.0189</td> <td>    0.007</td> <td>    2.882</td> <td> 0.004</td> <td>    0.006</td> <td>    0.032</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\")</th>                           <td>   -0.5532</td> <td>    0.546</td> <td>   -1.013</td> <td> 0.312</td> <td>   -1.627</td> <td>    0.521</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\")</th>                    <td>    0.0090</td> <td>    0.007</td> <td>    1.311</td> <td> 0.191</td> <td>   -0.004</td> <td>    0.023</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\")</th>                     <td>    0.0208</td> <td>    0.008</td> <td>    2.571</td> <td> 0.011</td> <td>    0.005</td> <td>    0.037</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\")</th>              <td>   -0.0002</td> <td> 9.06e-05</td> <td>   -2.277</td> <td> 0.023</td> <td>   -0.000</td> <td>-2.82e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Atk\")</th>                           <td>   -0.7277</td> <td>    0.506</td> <td>   -1.439</td> <td> 0.151</td> <td>   -1.722</td> <td>    0.267</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Atk\")</th>                    <td>    0.0136</td> <td>    0.005</td> <td>    2.682</td> <td> 0.008</td> <td>    0.004</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Atk\")</th>                     <td>    0.0146</td> <td>    0.007</td> <td>    2.139</td> <td> 0.033</td> <td>    0.001</td> <td>    0.028</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Atk\")</th>              <td>   -0.0002</td> <td>  5.4e-05</td> <td>   -3.383</td> <td> 0.001</td> <td>   -0.000</td> <td>-7.65e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>              <td>    0.0103</td> <td>    0.007</td> <td>    1.516</td> <td> 0.130</td> <td>   -0.003</td> <td>    0.024</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>       <td>   -0.0001</td> <td> 6.71e-05</td> <td>   -2.119</td> <td> 0.035</td> <td>   -0.000</td> <td>-1.03e-05</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th>        <td>   -0.0002</td> <td> 8.82e-05</td> <td>   -2.075</td> <td> 0.039</td> <td>   -0.000</td> <td>-9.62e-06</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")</th> <td>  2.03e-06</td> <td> 7.42e-07</td> <td>    2.734</td> <td> 0.007</td> <td>  5.7e-07</td> <td> 3.49e-06</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The condition number is large, 2.34e+09. This might indicate that there are<br/>strong multicollinearity or other numerical problems."
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Dep. Variable:}                         &        HP        & \\textbf{  R-squared:         } &     0.378   \\\\\n",
       "\\textbf{Model:}                                 &       OLS        & \\textbf{  Adj. R-squared:    } &     0.347   \\\\\n",
       "\\textbf{Method:}                                &  Least Squares   & \\textbf{  F-statistic:       } &     12.16   \\\\\n",
       "\\textbf{Date:}                                  & Thu, 14 Nov 2024 & \\textbf{  Prob (F-statistic):} &  4.20e-29   \\\\\n",
       "\\textbf{Time:}                                  &     17:54:48     & \\textbf{  Log-Likelihood:    } &   -1769.5   \\\\\n",
       "\\textbf{No. Observations:}                      &         400      & \\textbf{  AIC:               } &     3579.   \\\\\n",
       "\\textbf{Df Residuals:}                          &         380      & \\textbf{  BIC:               } &     3659.   \\\\\n",
       "\\textbf{Df Model:}                              &          19      & \\textbf{                     } &             \\\\\n",
       "\\textbf{Covariance Type:}                       &    nonrobust     & \\textbf{                     } &             \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lcccccc}\n",
       "                                                & \\textbf{coef} & \\textbf{std err} & \\textbf{t} & \\textbf{P$> |$t$|$} & \\textbf{[0.025} & \\textbf{0.975]}  \\\\\n",
       "\\midrule\n",
       "\\textbf{Intercept}                              &      95.1698  &       34.781     &     2.736  &         0.007        &       26.783    &      163.556     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Normal\")[T.True]}     &      18.3653  &        3.373     &     5.445  &         0.000        &       11.733    &       24.997     \\\\\n",
       "\\textbf{I(Q(\"Type 1\") == \"Water\")[T.True]}      &       9.2913  &        3.140     &     2.959  &         0.003        &        3.117    &       15.466     \\\\\n",
       "\\textbf{I(Generation == 2)[T.True]}             &       7.0711  &        2.950     &     2.397  &         0.017        &        1.271    &       12.871     \\\\\n",
       "\\textbf{I(Generation == 5)[T.True]}             &       7.8557  &        2.687     &     2.923  &         0.004        &        2.572    &       13.140     \\\\\n",
       "\\textbf{Attack}                                 &      -0.6975  &        0.458     &    -1.523  &         0.129        &       -1.598    &        0.203     \\\\\n",
       "\\textbf{Speed}                                  &      -1.8147  &        0.554     &    -3.274  &         0.001        &       -2.905    &       -0.725     \\\\\n",
       "\\textbf{Attack:Speed}                           &       0.0189  &        0.007     &     2.882  &         0.004        &        0.006    &        0.032     \\\\\n",
       "\\textbf{Q(\"Sp. Def\")}                           &      -0.5532  &        0.546     &    -1.013  &         0.312        &       -1.627    &        0.521     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\")}                    &       0.0090  &        0.007     &     1.311  &         0.191        &       -0.004    &        0.023     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\")}                     &       0.0208  &        0.008     &     2.571  &         0.011        &        0.005    &        0.037     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\")}              &      -0.0002  &     9.06e-05     &    -2.277  &         0.023        &       -0.000    &    -2.82e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Atk\")}                           &      -0.7277  &        0.506     &    -1.439  &         0.151        &       -1.722    &        0.267     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Atk\")}                    &       0.0136  &        0.005     &     2.682  &         0.008        &        0.004    &        0.024     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Atk\")}                     &       0.0146  &        0.007     &     2.139  &         0.033        &        0.001    &        0.028     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Atk\")}              &      -0.0002  &      5.4e-05     &    -3.383  &         0.001        &       -0.000    &    -7.65e-05     \\\\\n",
       "\\textbf{Q(\"Sp. Def\"):Q(\"Sp. Atk\")}              &       0.0103  &        0.007     &     1.516  &         0.130        &       -0.003    &        0.024     \\\\\n",
       "\\textbf{Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}       &      -0.0001  &     6.71e-05     &    -2.119  &         0.035        &       -0.000    &    -1.03e-05     \\\\\n",
       "\\textbf{Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")}        &      -0.0002  &     8.82e-05     &    -2.075  &         0.039        &       -0.000    &    -9.62e-06     \\\\\n",
       "\\textbf{Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")} &     2.03e-06  &     7.42e-07     &     2.734  &         0.007        &      5.7e-07    &     3.49e-06     \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\begin{tabular}{lclc}\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "%\\caption{OLS Regression Results}\n",
       "\\end{center}\n",
       "\n",
       "Notes: \\newline\n",
       " [1] Standard Errors assume that the covariance matrix of the errors is correctly specified. \\newline\n",
       " [2] The condition number is large, 2.34e+09. This might indicate that there are \\newline\n",
       " strong multicollinearity or other numerical problems."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                     HP   R-squared:                       0.378\n",
       "Model:                            OLS   Adj. R-squared:                  0.347\n",
       "Method:                 Least Squares   F-statistic:                     12.16\n",
       "Date:                Thu, 14 Nov 2024   Prob (F-statistic):           4.20e-29\n",
       "Time:                        17:54:48   Log-Likelihood:                -1769.5\n",
       "No. Observations:                 400   AIC:                             3579.\n",
       "Df Residuals:                     380   BIC:                             3659.\n",
       "Df Model:                          19                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==========================================================================================================\n",
       "                                             coef    std err          t      P>|t|      [0.025      0.975]\n",
       "----------------------------------------------------------------------------------------------------------\n",
       "Intercept                                 95.1698     34.781      2.736      0.007      26.783     163.556\n",
       "I(Q(\"Type 1\") == \"Normal\")[T.True]        18.3653      3.373      5.445      0.000      11.733      24.997\n",
       "I(Q(\"Type 1\") == \"Water\")[T.True]          9.2913      3.140      2.959      0.003       3.117      15.466\n",
       "I(Generation == 2)[T.True]                 7.0711      2.950      2.397      0.017       1.271      12.871\n",
       "I(Generation == 5)[T.True]                 7.8557      2.687      2.923      0.004       2.572      13.140\n",
       "Attack                                    -0.6975      0.458     -1.523      0.129      -1.598       0.203\n",
       "Speed                                     -1.8147      0.554     -3.274      0.001      -2.905      -0.725\n",
       "Attack:Speed                               0.0189      0.007      2.882      0.004       0.006       0.032\n",
       "Q(\"Sp. Def\")                              -0.5532      0.546     -1.013      0.312      -1.627       0.521\n",
       "Attack:Q(\"Sp. Def\")                        0.0090      0.007      1.311      0.191      -0.004       0.023\n",
       "Speed:Q(\"Sp. Def\")                         0.0208      0.008      2.571      0.011       0.005       0.037\n",
       "Attack:Speed:Q(\"Sp. Def\")                 -0.0002   9.06e-05     -2.277      0.023      -0.000   -2.82e-05\n",
       "Q(\"Sp. Atk\")                              -0.7277      0.506     -1.439      0.151      -1.722       0.267\n",
       "Attack:Q(\"Sp. Atk\")                        0.0136      0.005      2.682      0.008       0.004       0.024\n",
       "Speed:Q(\"Sp. Atk\")                         0.0146      0.007      2.139      0.033       0.001       0.028\n",
       "Attack:Speed:Q(\"Sp. Atk\")                 -0.0002    5.4e-05     -3.383      0.001      -0.000   -7.65e-05\n",
       "Q(\"Sp. Def\"):Q(\"Sp. Atk\")                  0.0103      0.007      1.516      0.130      -0.003       0.024\n",
       "Attack:Q(\"Sp. Def\"):Q(\"Sp. Atk\")          -0.0001   6.71e-05     -2.119      0.035      -0.000   -1.03e-05\n",
       "Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")           -0.0002   8.82e-05     -2.075      0.039      -0.000   -9.62e-06\n",
       "Attack:Speed:Q(\"Sp. Def\"):Q(\"Sp. Atk\")   2.03e-06   7.42e-07      2.734      0.007     5.7e-07    3.49e-06\n",
       "==============================================================================\n",
       "Omnibus:                      252.300   Durbin-Watson:                   1.953\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             3474.611\n",
       "Skew:                           2.438   Prob(JB):                         0.00\n",
       "Kurtosis:                      16.590   Cond. No.                     2.34e+09\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The condition number is large, 2.34e+09. This might indicate that there are\n",
       "strong multicollinearity or other numerical problems.\n",
       "\"\"\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhaps improve prediction...\n",
    "model7_linear_form = 'HP ~ Attack * Speed * Q(\"Sp. Def\") * Q(\"Sp. Atk\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form += ' + I(Generation==2)'\n",
    "model7_linear_form += ' + I(Generation==5)'\n",
    "\n",
    "model7_spec = smf.ols(formula=model7_linear_form, data=pokeaman_train)\n",
    "model7_fit = model7_spec.fit()\n",
    "model7_fit.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "57b1b83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456\n",
      "'Out of sample' R-squared: 0.35055389205977444\n"
     ]
    }
   ],
   "source": [
    "yhat_model7 = model7_fit.predict(pokeaman_test)\n",
    "y = pokeaman_test.HP\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared)\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "787ef87f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>    15.4</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } &     15.4  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# And here's a slight change that seems to perhas improve prediction...\n",
    "model7_linear_form_CS = 'HP ~ scale(center(Attack)) * scale(center(Speed))'\n",
    "model7_linear_form_CS += ' * scale(center(Q(\"Sp. Def\"))) * scale(center(Q(\"Sp. Atk\")))'\n",
    "# We DO NOT center and scale indicator variables\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Normal\")'\n",
    "model7_linear_form_CS += ' + I(Q(\"Type 1\")==\"Water\")'\n",
    "model7_linear_form_CS += ' + I(Generation==2)'\n",
    "model7_linear_form_CS += ' + I(Generation==5)'\n",
    "\n",
    "model7_CS_spec = smf.ols(formula=model7_linear_form_CS, data=pokeaman_train)\n",
    "model7_CS_fit = model7_CS_spec.fit()\n",
    "model7_CS_fit.summary().tables[-1] \n",
    "# \"Cond. No.\" is NOW 15.4 due to centering and scaling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da29276d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>252.300</td> <th>  Durbin-Watson:     </th> <td>   1.953</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td>3474.611</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 2.438</td>  <th>  Prob(JB):          </th> <td>    0.00</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td>16.590</td>  <th>  Cond. No.          </th> <td>2.34e+09</td>\n",
       "</tr>\n",
       "</table>"
      ],
      "text/latex": [
       "\\begin{center}\n",
       "\\begin{tabular}{lclc}\n",
       "\\toprule\n",
       "\\textbf{Omnibus:}       & 252.300 & \\textbf{  Durbin-Watson:     } &    1.953  \\\\\n",
       "\\textbf{Prob(Omnibus):} &   0.000 & \\textbf{  Jarque-Bera (JB):  } & 3474.611  \\\\\n",
       "\\textbf{Skew:}          &   2.438 & \\textbf{  Prob(JB):          } &     0.00  \\\\\n",
       "\\textbf{Kurtosis:}      &  16.590 & \\textbf{  Cond. No.          } & 2.34e+09  \\\\\n",
       "\\bottomrule\n",
       "\\end{tabular}\n",
       "\\end{center}"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.table.SimpleTable'>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# \"Cond. No.\" WAS 2,340,000,000 WITHOUT to centering and scaling\n",
    "model7_fit.summary().tables[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff611c7b",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f2f03d5",
   "metadata": {},
   "source": [
    "Here’s a summary of our exchanges for your homework submission:\n",
    "\n",
    "---\n",
    "\n",
    "**Objective**: To understand the rationale and principles behind the progression of linear models (Model 5, Model 6, and Model 7) in terms of model complexity, predictor selection, and multicollinearity.\n",
    "\n",
    "### Key Points Discussed\n",
    "\n",
    "1. **Development of Model 5**:\n",
    "   - Model 5 builds on the simpler models (Model 3 and Model 4) by including additional predictors such as `Speed`, `Legendary`, `Sp. Def`, `Sp. Atk`, and categorical variables like `Generation` and `Type`.\n",
    "   - The principle behind Model 5 is to broaden the scope of predictors by capturing a more comprehensive set of main effects, without adding interactions, to enhance model accuracy without overfitting.\n",
    "\n",
    "2. **Development of Model 6**:\n",
    "   - Model 6 narrows down Model 5 by retaining only the most statistically significant predictors identified in the previous model.\n",
    "   - The goal is to simplify the model, hypothesizing that fewer, carefully selected predictors might improve out-of-sample performance by reducing multicollinearity and the risk of overfitting.\n",
    "\n",
    "3. **Development of Model 7**:\n",
    "   - Model 7 builds on Model 6 by reintroducing selected interaction terms (e.g., `Attack * Speed * Sp. Def * Sp. Atk`) to capture combined effects that may enhance predictive power.\n",
    "   - This model also uses centering and scaling for continuous predictors to address multicollinearity introduced by interactions, with the aim of balancing model complexity and generalizability.\n",
    "\n",
    "4. **Progression Summary**:\n",
    "   - The progression from Model 5 to Model 7 reflects a balance-seeking approach. Model 5 broadens the predictor set, Model 6 refines it to focus on significant predictors, and Model 7 explores combined effects with carefully chosen interactions and multicollinearity control.\n",
    "   - Centering and scaling in Model 7 help manage multicollinearity, particularly important in complex models with interactions.\n",
    "\n",
    "---\n",
    "\n",
    "This summary provides a structured record of our discussion, explaining the step-by-step development and rationale behind each model extension. Let me know if you need any more details for your submission!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fec262a",
   "metadata": {},
   "source": [
    "#### Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "750ae25f",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/6736196a-cad8-8010-9a44-44a87903b88e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2b13c02",
   "metadata": {},
   "source": [
    "# Question 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "dd6e2c8c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.formula.api as smf\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Define the linear model formula based on model3's structure\n",
    "linear_form = 'HP ~ Attack + Defense'\n",
    "\n",
    "# Set the number of repetitions\n",
    "reps = 100\n",
    "in_sample_Rsquared = np.array([0.0] * reps)\n",
    "out_of_sample_Rsquared = np.array([0.0] * reps)\n",
    "\n",
    "# Perform repeated train-test splits and model fitting\n",
    "for i in range(reps):\n",
    "    # Randomly split data without setting a seed\n",
    "    pokeaman_train, pokeaman_test = train_test_split(pokeaman, train_size=0.5)\n",
    "    \n",
    "    # Fit the model on the training data\n",
    "    model_fit = smf.ols(formula=linear_form, data=pokeaman_train).fit()\n",
    "    \n",
    "    # Collect in-sample R-squared\n",
    "    in_sample_Rsquared[i] = model_fit.rsquared\n",
    "    \n",
    "    # Predict on the testing data and collect out-of-sample R-squared\n",
    "    out_of_sample_Rsquared[i] = np.corrcoef(pokeaman_test.HP, model_fit.predict(pokeaman_test))[0, 1]**2\n",
    "\n",
    "# Create a DataFrame to organize the R-squared values\n",
    "df = pd.DataFrame({\n",
    "    \"In Sample Performance (R-squared)\": in_sample_Rsquared,\n",
    "    \"Out of Sample Performance (R-squared)\": out_of_sample_Rsquared\n",
    "})\n",
    "\n",
    "# Visualize the results using Plotly\n",
    "fig = px.scatter(df, x=\"In Sample Performance (R-squared)\", y=\"Out of Sample Performance (R-squared)\",\n",
    "                 title=\"In-Sample vs. Out-of-Sample R-squared Across Repeated Splits\")\n",
    "# Add a reference line y = x to show where in-sample and out-of-sample performance are equal\n",
    "fig.add_trace(go.Scatter(x=[0, 1], y=[0, 1], mode=\"lines\", name=\"y=x\", line=dict(dash=\"dash\")))\n",
    "\n",
    "# Show the plot\n",
    "fig.show(renderer = 'jpg')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb686f7b",
   "metadata": {},
   "source": [
    "#### Explanation \n",
    "1. **Repeated Train-Test Splits**: By re-splitting the data in each iteration without setting a fixed random seed, we observe natural variations in how the training and testing sets are formed. This randomness in splitting introduces variability in the model’s \"in-sample\" and \"out-of-sample\" R-squared values.\n",
    "\n",
    "2. **Model Fitting and R-squared Collection**: For each split, we fit a linear model using `Attack` and `Defense` as predictors of `HP`. We calculate:\n",
    "   - **In-Sample R-squared**: The R-squared value on the training set, representing the model’s fit on the data it was trained on.\n",
    "   - **Out-of-Sample R-squared**: The R-squared value on the testing set, indicating the model’s predictive accuracy on unseen data.\n",
    "\n",
    "3. **Visualization**: The scatter plot compares in-sample and out-of-sample R-squared values across repetitions. The line `y = x` serves as a reference to see if the in-sample and out-of-sample performances align (indicating generalizability) or if the in-sample performance tends to exceed out-of-sample performance (indicating potential overfitting).\n",
    "\n",
    "#### Purpose\n",
    "\n",
    "This demonstration illustrates the **variability in model performance metrics** due to different data splits. Observing fluctuations between in-sample and out-of-sample R-squared values helps us understand:\n",
    "   - **Overfitting**: Consistently higher in-sample R-squared values than out-of-sample R-squared values indicate overfitting, where the model learns patterns specific to the training set rather than generalizable patterns.\n",
    "   - **Random Sampling Variability**: Occasionally, we may observe out-of-sample R-squared values that exceed in-sample R-squared values, a result of random sampling. This occurs due to a favorable arrangement of testing data or due to the model's variability in fit across splits.\n",
    "   \n",
    "#### Summary Explanation of Results\n",
    "\n",
    "This approach demonstrates the influence of random sampling on model performance metrics. Repeatedly fitting the model with varied splits reveals how sensitive performance metrics are to sample differences, providing insights into the model's robustness and potential overfitting. By analyzing these fluctuations, we gain a deeper understanding of the model’s generalizability and the role of data variability in model evaluation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09368e71",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39b4215e",
   "metadata": {},
   "source": [
    "Here’s a summary of our exchanges for your homework submission:\n",
    "\n",
    "---\n",
    "\n",
    "**Objective**: To write a `for` loop to create, collect, and visualize multiple paired \"in-sample\" and \"out-of-sample\" R-squared values by randomly re-splitting data without a fixed seed. We also aimed to interpret the variability in model performance metrics due to repeated random sampling.\n",
    "\n",
    "### Key Points Discussed\n",
    "\n",
    "1. **Setting Up the Code**:\n",
    "   - We adapted code to perform a 50-50 train-test split repeatedly, fit a linear model on `Attack` and `Defense` as predictors of `HP`, and calculated \"in-sample\" and \"out-of-sample\" R-squared values.\n",
    "   - By avoiding a fixed seed within each iteration, we introduced variability in train-test splits, which allowed us to capture natural fluctuations in model performance across different samples.\n",
    "\n",
    "2. **Collecting and Visualizing R-squared Values**:\n",
    "   - For each iteration, we stored the \"in-sample\" R-squared (from the training data) and \"out-of-sample\" R-squared (from the testing data).\n",
    "   - We created a scatter plot with `plotly` to compare in-sample vs. out-of-sample R-squared values across repetitions, adding a reference line (`y=x`) to show where in-sample and out-of-sample performances would align.\n",
    "\n",
    "3. **Purpose and Meaning of Results**:\n",
    "   - **Variability in Performance Metrics**: Observing variations in in-sample and out-of-sample R-squared values highlights the model's sensitivity to different data splits.\n",
    "   - **Overfitting Detection**: Consistently higher in-sample R-squared values compared to out-of-sample values indicate overfitting, where the model fits the training data well but performs less effectively on unseen data.\n",
    "   - **Random Sampling Effects**: Occasionally, out-of-sample R-squared values may exceed in-sample values due to random sampling, not underfitting. This shows how data arrangement affects performance metrics, providing insights into the model's generalizability and stability across different samples.\n",
    "\n",
    "### Summary Explanation\n",
    "This exercise demonstrates how repeated random sampling impacts model performance, showing the effects of variability in in-sample and out-of-sample R-squared values. By analyzing these fluctuations, we gain a deeper understanding of the model’s robustness and potential overfitting, as well as the importance of accounting for data variability in model evaluation.\n",
    "\n",
    "---\n",
    "\n",
    "This summary provides a structured record of our discussion and code, explaining the purpose and interpretation of results. Let me know if you need further details!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1ffec81",
   "metadata": {},
   "source": [
    "#### Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf21dad3",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/6736196a-cad8-8010-9a44-44a87903b88e"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5825b26f",
   "metadata": {},
   "source": [
    "# Question 9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5b79f11b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.00018905947734540018 (original)\n",
      "'In sample' R-squared:     0.5726118179916575 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.11151363354803218 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model7_gen1_predict_future_fit = model7_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model7_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f5b52ceb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.37818209127432456 (original)\n",
      "'Out of sample' R-squared: 0.00018905947734540018 (original)\n",
      "'In sample' R-squared:     0.3904756578094535 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.23394915464343125 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model7_gen1to5_predict_future = smf.ols(formula=model7_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model7_gen1to5_predict_future_fit = model7_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model7_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model7)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model7_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model7_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f8bb9c63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.0003901627672308394 (original)\n",
      "'In sample' R-squared:     0.4433880517727282 (gen1_predict_future)\n",
      "'Out of sample' R-squared: 0.1932858534276128 (gen1_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model6_gen1_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation==1])\n",
    "model6_gen1_predict_future_fit = model6_gen1_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1_predict_future_fit.rsquared, \"(gen1_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation!=1].HP\n",
    "yhat = model6_gen1_predict_future_fit.predict(pokeaman[pokeaman.Generation!=1])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1_predict_future)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "495c244f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'In sample' R-squared:     0.3326310334310908 (original)\n",
      "'Out of sample' R-squared: 0.0003901627672308394 (original)\n",
      "'In sample' R-squared:     0.33517279824114776 (gen1to5_predict_future)\n",
      "'Out of sample' R-squared: 0.26262690178799936 (gen1to5_predict_future)\n"
     ]
    }
   ],
   "source": [
    "model6_gen1to5_predict_future = smf.ols(formula=model6_linear_form,\n",
    "                                   data=pokeaman[pokeaman.Generation!=6])\n",
    "model6_gen1to5_predict_future_fit = model6_gen1to5_predict_future.fit()\n",
    "print(\"'In sample' R-squared:    \", model6_fit.rsquared, \"(original)\")\n",
    "y = pokeaman_test.HP\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat_model6)[0,1]**2, \"(original)\")\n",
    "print(\"'In sample' R-squared:    \", model6_gen1to5_predict_future_fit.rsquared, \"(gen1to5_predict_future)\")\n",
    "y = pokeaman[pokeaman.Generation==6].HP\n",
    "yhat = model6_gen1to5_predict_future_fit.predict(pokeaman[pokeaman.Generation==6])\n",
    "print(\"'Out of sample' R-squared:\", np.corrcoef(y,yhat)[0,1]**2, \"(gen1to5_predict_future)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b151b954",
   "metadata": {},
   "source": [
    "1. **Complexity and Generalizability**: \n",
    "   - **Model 7** is more complex than **Model 6**, with numerous interaction terms. While Model 7 shows slightly better out-of-sample performance on a randomly split test set, its complexity increases the risk of overfitting. Complex models like Model 7 can \"detect\" associations in training data that might not be real patterns but rather random fluctuations, especially if they are overly tailored to specific features of the training data.\n",
    "   - **Model 6**, being simpler, has fewer interaction terms, and its coefficients generally have stronger statistical support (lower p-values). This simplicity not only makes Model 6 easier to interpret but may also allow it to generalize better in real-world scenarios.\n",
    "\n",
    "2. **Real-World Predictive Evaluation**:\n",
    "   - This illustration uses a **sequential approach to training and testing**, aligning with how predictive models might be applied in real-world scenarios. Instead of randomly splitting data, we simulate a scenario where older data (from Generation 1 or Generations 1-5) is used to predict outcomes in newer data (e.g., Generation 6).\n",
    "   - In practical terms, the training set consists of older data, and the model is tested on data that the model has not yet \"seen\"—mimicking a real-world setting where data arrives over time and models are used to forecast future outcomes.\n",
    "\n",
    "3. **Results and Interpretation**:\n",
    "   - **In-Sample vs. Out-of-Sample R-squared**: Both models are evaluated on their in-sample (training) R-squared and their out-of-sample (testing) R-squared using sequential data splits.\n",
    "   - **Observation of Generalizability Issues**: Model 7, due to its complexity, exhibits more significant declines in out-of-sample R-squared when used to predict future data. This suggests that its performance advantage observed in idealized test splits may not hold in practical, time-sequenced applications.\n",
    "   - **Preference for Simplicity and Interpretability**: Model 6’s simpler, more interpretable structure makes it a preferable choice for sequential prediction, as it’s less prone to overfitting and easier to understand, even if its raw out-of-sample performance is slightly lower than Model 7’s.\n",
    "\n",
    "#### Meaning of the Illustration \n",
    "This illustration emphasizes that while complex models can sometimes deliver higher out-of-sample performance on randomly split data, simpler models may generalize better and remain more interpretable in real-world applications. Using older data to predict newer data, as shown here, highlights that Model 7’s complexity doesn’t necessarily improve generalizability. In fact, it can reduce the model’s reliability on truly unseen data, underscoring that simpler, more interpretable models like Model 6 often provide more robust and consistent predictions, especially when applied to real-world scenarios where data arrives sequentially."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "221fbda3",
   "metadata": {},
   "source": [
    "#### Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46ac8760",
   "metadata": {},
   "source": [
    "Here’s a summary of our exchanges for your homework submission:\n",
    "\n",
    "---\n",
    "\n",
    "**Objective**: To understand the implications of model complexity on generalizability, specifically using a sequential data approach to assess Models 6 and 7.\n",
    "\n",
    "### Key Points Discussed\n",
    "\n",
    "1. **Comparison of Model Complexity and Generalizability**:\n",
    "   - Model 7, with many interaction terms, is more complex than Model 6. While Model 7 demonstrated slightly better out-of-sample performance on a random train-test split, its complexity increases the risk of overfitting, potentially detecting associations specific to the training data that may not generalize.\n",
    "   - Model 6, as a simpler model, has fewer interaction terms and shows stronger statistical support for its coefficients. This simplicity not only makes Model 6 easier to interpret but also supports better generalizability, especially in real-world applications.\n",
    "\n",
    "2. **Sequential Approach to Model Evaluation**:\n",
    "   - We explored a more practical evaluation by using older data to predict newer data, simulating a real-world scenario where data arrives over time. Instead of a random split, data from earlier generations (Generation 1 or Generations 1-5) was used to train the models, which were then tested on future generations (e.g., Generation 6).\n",
    "   - This approach allows us to see how well each model generalizes to data that it hasn’t \"seen\" before, more closely mimicking real-world predictive applications.\n",
    "\n",
    "3. **Insights on Model Performance**:\n",
    "   - **In-Sample vs. Out-of-Sample R-squared**: Sequentially evaluating in-sample and out-of-sample R-squared values revealed that Model 7, due to its complexity, experienced a more significant decline in predictive accuracy on future data. This suggests that its slight performance advantage in a randomized split test may not hold up in sequential, real-world data applications.\n",
    "   - **Preference for Model Simplicity**: Given that Model 6 maintains better interpretability and relatively consistent generalizability, it’s often preferable to a more complex model like Model 7, especially when prediction reliability and ease of interpretation are crucial.\n",
    "\n",
    "### Summary Explanation\n",
    "This discussion illustrated that while complex models might yield higher out-of-sample performance on randomly split data, simpler models often generalize more reliably. Sequential evaluation, which uses past data to predict future outcomes, demonstrated that Model 6’s simplicity makes it more robust and interpretable for real-world applications, where data arrives sequentially. This underscores the principle that simplicity in modeling can lead to more consistent predictions, especially when performance between models is similar.\n",
    "\n",
    "---\n",
    "\n",
    "This summary provides a record of our discussions, highlighting the implications of model complexity, generalizability, and interpretability in a sequential data context. Let me know if any additional details are needed!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f484795",
   "metadata": {},
   "source": [
    "#### Link"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f54d6e78",
   "metadata": {},
   "source": [
    "https://chatgpt.com/share/6736196a-cad8-8010-9a44-44a87903b88e"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
